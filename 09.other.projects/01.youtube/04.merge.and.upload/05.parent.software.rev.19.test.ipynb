{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00e62070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:35:55 - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube authentication complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:36:05 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Statistics\\Lynda\\Everyday Statistics, with Eddie Davila Update 20190118\n",
      "14:36:05 - Found 16 videos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 tutorial folders.\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Statistics\\Lynda\\Everyday Statistics, with Eddie Davila Update 20190118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:36:08 - Total duration: 0.96 hours\n",
      "14:36:08 - Generated title: Topics - Statistics - Lynda - Everyday Statistics, with Eddie Davila Update 20190118\n",
      "14:36:16 - Videos merged successfully for part single\n",
      "14:36:17 - Uploading with title: 'Topics - Statistics - Lynda - Everyday Statistics, with Eddie Davila Update 20190118' (length: 84)\n",
      "14:36:17 - file_cache is only supported with oauth2client<4.0.0\n",
      "14:37:09 - Upload successful! Video ID: BSXsayasQaM\n",
      "14:37:09 - Video URL: https://www.youtube.com/watch?v=BSXsayasQaM\n",
      "14:37:09 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Statistics\\Udemy\\Learn Statistics From Numbers\n",
      "14:37:09 - Found 7 videos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Statistics\\Udemy\\Learn Statistics From Numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:37:10 - Total duration: 0.92 hours\n",
      "14:37:10 - Generated title: Topics - Statistics - Udemy - Learn Statistics From Numbers\n",
      "14:37:16 - Videos merged successfully for part single\n",
      "14:37:17 - Uploading with title: 'Topics - Statistics - Udemy - Learn Statistics From Numbers' (length: 59)\n",
      "14:37:17 - file_cache is only supported with oauth2client<4.0.0\n",
      "14:38:06 - Upload successful! Video ID: MdnHhsLEgAI\n",
      "14:38:06 - Video URL: https://www.youtube.com/watch?v=MdnHhsLEgAI\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import ffmpeg\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import ssl\n",
    "import string\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler('video_processing.log', encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "TOKEN_FILE = \"token.json\"\n",
    "SCOPES = [\"https://www.googleapis.com/auth/youtube.upload\"]\n",
    "\n",
    "os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
    "os.environ['PYTHONHTTPSVERIFY'] = '0'\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Add global lists to track failed conversions and merges\n",
    "FAILED_CONVERSIONS = []\n",
    "FAILED_MERGES = []\n",
    "SKIPPED_FILES = []\n",
    "\n",
    "def get_authenticated_service(client_secrets_file: str):\n",
    "    creds = None\n",
    "    if os.path.exists(TOKEN_FILE):\n",
    "        creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(client_secrets_file, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open(TOKEN_FILE, 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return build('youtube', 'v3', credentials=creds)\n",
    "\n",
    "def get_structured_title(input_path: str) -> str:\n",
    "    try:\n",
    "        path = Path(input_path)\n",
    "        parts = list(path.parts)[-4:]\n",
    "        return ' - '.join(parts)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in get_structured_title: {str(e)}\")\n",
    "        return os.path.basename(input_path)\n",
    "\n",
    "def collect_videos(folder_path: str) -> List[Tuple[str, str]]:\n",
    "    video_files = []\n",
    "    extensions = ('*.mp4', '*.avi', '*.mkv', '*.mov', '*.flv', '*.rmvb')\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # Skip any 'converted_videos' subfolder\n",
    "        if 'converted_videos' in root.split(os.sep):\n",
    "            continue\n",
    "        for ext in extensions:\n",
    "            for file in glob.glob(os.path.join(root, ext)):\n",
    "                rel_path = os.path.relpath(file, folder_path)\n",
    "                video_files.append((file, rel_path))\n",
    "    return sorted(video_files)\n",
    "\n",
    "def merge_videos(video_files: List[Tuple[str, str]], output_path: str) -> bool:\n",
    "    try:\n",
    "        valid_files = []\n",
    "        file_list_path = None\n",
    "        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.txt', encoding='utf-8') as tmpfile:\n",
    "            for full_path, _ in video_files:\n",
    "                if not os.path.exists(full_path):\n",
    "                    logging.error(f\"File does not exist, skipping: {full_path}\")\n",
    "                    SKIPPED_FILES.append(full_path)\n",
    "                    continue\n",
    "                if get_video_duration(full_path) <= 0:\n",
    "                    logging.error(f\"File is not a valid video or is corrupt, skipping: {full_path}\")\n",
    "                    SKIPPED_FILES.append(full_path)\n",
    "                    continue\n",
    "                abs_path = os.path.abspath(full_path).replace('\\\\', '/')\n",
    "                abs_path = abs_path.replace(\"'\", \"'\\\\''\")\n",
    "                tmpfile.write(f\"file '{abs_path}'\\n\")\n",
    "                valid_files.append(full_path)\n",
    "            file_list_path = tmpfile.name\n",
    "        if not valid_files:\n",
    "            logging.error(f\"No valid files to merge for output: {output_path}\")\n",
    "            FAILED_MERGES.append(output_path)\n",
    "            return False\n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-f', 'concat',\n",
    "            '-safe', '0',\n",
    "            '-i', file_list_path,\n",
    "            '-c', 'copy',\n",
    "            output_path,\n",
    "            '-y'\n",
    "        ]\n",
    "        process = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')\n",
    "        if process.returncode != 0:\n",
    "            logging.error(f\"Error merging videos: {process.stderr}\")\n",
    "            FAILED_MERGES.append(output_path)\n",
    "            # Log the list of files in this batch for debugging\n",
    "            logging.error(f\"Files in failed batch merge for {output_path}: {valid_files}\")\n",
    "        return process.returncode == 0\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error merging videos: {str(e)}\")\n",
    "        FAILED_MERGES.append(output_path)\n",
    "        return False\n",
    "    finally:\n",
    "        if 'file_list_path' in locals() and file_list_path and os.path.exists(file_list_path):\n",
    "            os.remove(file_list_path)\n",
    "\n",
    "def convert_video(input_path: str, output_path: str) -> bool:\n",
    "    try:\n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', input_path,\n",
    "            '-vf', 'scale=-2:720',\n",
    "            '-r', '30',\n",
    "            '-c:v', 'libx264',\n",
    "            '-preset', 'fast',\n",
    "            '-crf', '23',\n",
    "            '-c:a', 'aac',\n",
    "            '-b:a', '128k',\n",
    "            '-y',\n",
    "            output_path\n",
    "        ]\n",
    "        process = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')\n",
    "        if process.returncode != 0:\n",
    "            logging.error(f\"Error converting {input_path}: {process.stderr}\")\n",
    "            FAILED_CONVERSIONS.append(input_path)\n",
    "        return process.returncode == 0\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception converting {input_path}: {str(e)}\")\n",
    "        FAILED_CONVERSIONS.append(input_path)\n",
    "        return False\n",
    "\n",
    "def convert_all_videos(video_files: List[Tuple[str, str]], converted_dir: str) -> List[Tuple[str, str]]:\n",
    "    os.makedirs(converted_dir, exist_ok=True)\n",
    "    converted_files = []\n",
    "    for full_path, rel_path in video_files:\n",
    "        base_name = os.path.splitext(rel_path)[0] + '.mp4'\n",
    "        out_path = os.path.join(converted_dir, base_name)\n",
    "        out_dir = os.path.dirname(out_path)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        if convert_video(full_path, out_path):\n",
    "            converted_files.append((out_path, rel_path))\n",
    "        else:\n",
    "            logging.error(f\"Failed to convert {full_path}\")\n",
    "    return converted_files\n",
    "\n",
    "def sanitize_description(desc: str) -> str:\n",
    "    \"\"\"Remove non-printable characters and truncate to 5000 chars for YouTube description.\"\"\"\n",
    "    desc = re.sub(r'[^\\x09\\x0A\\x0D\\x20-\\x7E\\u00A0-\\uD7FF\\uE000-\\uFFFD]', '', desc)\n",
    "    return desc[:5000]\n",
    "\n",
    "def generate_timestamps(video_files: List[Tuple[str, str]]) -> str:\n",
    "    timestamps = []\n",
    "    current_time = 0\n",
    "    for full_path, rel_path in video_files:\n",
    "        hours = int(current_time // 3600)\n",
    "        minutes = int((current_time % 3600) // 60)\n",
    "        seconds = int(current_time % 60)\n",
    "        timestamp = f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "        video_name = os.path.splitext(os.path.basename(rel_path))[0]\n",
    "        timestamps.append(f\"{timestamp} - {video_name}\")\n",
    "        try:\n",
    "            cmd = [\n",
    "                'ffprobe', '-v', 'error', '-show_entries', 'format=duration',\n",
    "                '-of', 'default=noprint_wrappers=1:nokey=1', full_path\n",
    "            ]\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            if result.returncode == 0 and result.stdout.strip():\n",
    "                duration = float(result.stdout.strip())\n",
    "                current_time += duration\n",
    "            else:\n",
    "                logging.error(f\"ffprobe error for {full_path}: {result.stderr.strip()}\")\n",
    "                current_time += 0\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Exception running ffprobe for {full_path}: {str(e)}\")\n",
    "            current_time += 0\n",
    "    return '\\n'.join(timestamps)\n",
    "\n",
    "def upload_to_youtube(youtube, video_path: str, title: str, description: str) -> Optional[str]:\n",
    "    try:\n",
    "        body = {\n",
    "            'snippet': {\n",
    "                'title': title,\n",
    "                'description': description,\n",
    "                'tags': ['tutorial', 'education']\n",
    "            },\n",
    "            'status': {\n",
    "                'privacyStatus': 'unlisted',\n",
    "                'selfDeclaredMadeForKids': False\n",
    "            }\n",
    "        }\n",
    "        insert_request = youtube.videos().insert(\n",
    "            part=','.join(body.keys()),\n",
    "            body=body,\n",
    "            media_body=MediaFileUpload(video_path, chunksize=-1, resumable=True)\n",
    "        )\n",
    "        response = None\n",
    "        while response is None:\n",
    "            status, response = insert_request.next_chunk()\n",
    "            if status:\n",
    "                logging.info(f\"Upload {int(status.progress() * 100)}% complete\")\n",
    "        return response['id']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error uploading to YouTube: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def cleanup_and_save_link(folder_path: str, video_id: str, title: str, merged_path: str, converted_dir: Optional[str] = None, delete_all: bool = False, original_files: Optional[list] = None):\n",
    "    link_file = os.path.join(folder_path, \"youtube link.txt\")\n",
    "    with open(link_file, 'w') as f:\n",
    "        f.write(f\"Title: {title}\\n\")\n",
    "        f.write(f\"URL: https://www.youtube.com/watch?v={video_id}\\n\")\n",
    "        f.write(f\"Uploaded: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    # Delete merged video\n",
    "    if os.path.exists(merged_path):\n",
    "        try:\n",
    "            os.remove(merged_path)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to delete merged video: {merged_path}: {str(e)}\")\n",
    "    # Delete all video files in the top-level tutorial folder (except the link file)\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if item_path == link_file:\n",
    "            continue\n",
    "        if os.path.isfile(item_path) and item_path.lower().endswith((\".mp4\", \".flv\", \".avi\", \".mkv\", \".mov\", \".rmvb\")):\n",
    "            try:\n",
    "                os.remove(item_path)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to delete video file: {item_path}: {str(e)}\")\n",
    "        elif os.path.isdir(item_path):\n",
    "            try:\n",
    "                shutil.rmtree(item_path)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to delete folder: {item_path}: {str(e)}\")\n",
    "    # Remove converted_videos folder if present\n",
    "    if converted_dir and os.path.exists(converted_dir):\n",
    "        try:\n",
    "            shutil.rmtree(converted_dir)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to delete converted_videos: {converted_dir}: {str(e)}\")\n",
    "    # If delete_all is True, remove all original video files in all subfolders as well\n",
    "    if delete_all:\n",
    "        # Remove all original video files (not just converted) in all subfolders\n",
    "        if original_files:\n",
    "            for orig_file in original_files:\n",
    "                if os.path.exists(orig_file):\n",
    "                    try:\n",
    "                        os.remove(orig_file)\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Failed to delete original video file: {orig_file}: {str(e)}\")\n",
    "        else:\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith((\".mp4\", \".avi\", \".mkv\", \".mov\", \".flv\", \".rmvb\")):\n",
    "                        try:\n",
    "                            os.remove(os.path.join(root, file))\n",
    "                        except Exception as e:\n",
    "                            logging.error(f\"Failed to delete {file}: {str(e)}\")\n",
    "                for dir in dirs:\n",
    "                    dir_path = os.path.join(root, dir)\n",
    "                    if dir_path != converted_dir and os.path.exists(dir_path):\n",
    "                        try:\n",
    "                            shutil.rmtree(dir_path)\n",
    "                        except Exception as e:\n",
    "                            logging.error(f\"Failed to delete directory {dir_path}: {str(e)}\")\n",
    "\n",
    "def get_video_duration(video_path: str) -> float:\n",
    "    try:\n",
    "        probe = ffmpeg.probe(video_path)\n",
    "        for stream in probe['streams']:\n",
    "            if 'duration' in stream:\n",
    "                return float(stream['duration'])\n",
    "        return float(probe['format']['duration'])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error getting duration for {video_path}: {str(e)}\")\n",
    "        SKIPPED_FILES.append(video_path)\n",
    "        return 0.0\n",
    "\n",
    "def sanitize_title(title):\n",
    "    # Remove non-printable characters\n",
    "    printable = set(string.printable)\n",
    "    title = ''.join(filter(lambda x: x in printable, title))\n",
    "    # Truncate to 100 chars\n",
    "    return title[:100]\n",
    "\n",
    "def split_videos_by_duration(video_files: List[Tuple[str, str]], durations: List[float], max_duration: float = 41400) -> List[Tuple[List[Tuple[str, str]], List[float], str]]:\n",
    "    \"\"\"\n",
    "    Splits the list of video files into as many parts as needed so that each part's total duration is <= max_duration (default 11.5 hours).\n",
    "    Returns a list of tuples: (split_files, split_durations, suffix)\n",
    "    \"\"\"\n",
    "    splits = []\n",
    "    part = []\n",
    "    part_durations = []\n",
    "    part_total = 0.0\n",
    "    part_idx = 1\n",
    "    for (file, rel), dur in zip(video_files, durations):\n",
    "        if part_total + dur > max_duration and part:\n",
    "            splits.append((part, part_durations, f\"{part_idx:02d}\"))\n",
    "            part = []\n",
    "            part_durations = []\n",
    "            part_total = 0.0\n",
    "            part_idx += 1\n",
    "        part.append((file, rel))\n",
    "        part_durations.append(dur)\n",
    "        part_total += dur\n",
    "    if part:\n",
    "        splits.append((part, part_durations, f\"{part_idx:02d}\"))\n",
    "    return splits\n",
    "\n",
    "def batch_merge(video_files: List[Tuple[str, str]], batch_size: int, temp_dir: str) -> List[Tuple[str, str]]:\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    batch_files = []\n",
    "    for i in range(0, len(video_files), batch_size):\n",
    "        batch = video_files[i:i+batch_size]\n",
    "        batch_path = os.path.join(temp_dir, f\"batch_{i//batch_size:03d}.mp4\")\n",
    "        if merge_videos(batch, batch_path):\n",
    "            batch_files.append((batch_path, f\"batch_{i//batch_size:03d}.mp4\"))\n",
    "        else:\n",
    "            logging.error(f\"Batch merge failed for {batch_path}\")\n",
    "            FAILED_MERGES.append(batch_path)\n",
    "    return batch_files\n",
    "\n",
    "def process_folder(folder_path: str, client_secrets_file: str):\n",
    "    try:\n",
    "        if os.path.basename(folder_path) == 'converted_videos':\n",
    "            logging.error(\"Refusing to process a folder named 'converted_videos' to avoid recursion.\")\n",
    "            return\n",
    "        logging.info(f\"Processing folder: {folder_path}\")\n",
    "        video_files = collect_videos(folder_path)\n",
    "        if not video_files:\n",
    "            logging.error(\"No video files found\")\n",
    "            return\n",
    "        logging.info(f\"Found {len(video_files)} videos\")\n",
    "        # Calculate total duration\n",
    "        total_duration = 0\n",
    "        durations = []\n",
    "        for file, _ in video_files:\n",
    "            d = get_video_duration(file)\n",
    "            if d == 0.0:\n",
    "                logging.error(f\"Skipping unreadable/corrupt file: {file}\")\n",
    "                continue\n",
    "            durations.append(d)\n",
    "            total_duration += d\n",
    "        if not durations:\n",
    "            logging.error(\"No valid video files after filtering corrupt/unreadable files.\")\n",
    "            return\n",
    "        logging.info(f\"Total duration: {total_duration/3600:.2f} hours\")\n",
    "        title_base = get_structured_title(folder_path)\n",
    "        if not title_base or not title_base.strip():\n",
    "            title_base = os.path.basename(folder_path)\n",
    "        logging.info(f\"Generated title: {title_base}\")\n",
    "        # Split into as many parts as needed so each is <= 11.5 hours\n",
    "        if total_duration > 41400 and len(video_files) > 1:\n",
    "            splits = split_videos_by_duration(video_files, durations, max_duration=41400)\n",
    "        else:\n",
    "            splits = [(video_files, durations, None)]\n",
    "        for idx, (split_files, split_durations, suffix) in enumerate(splits):\n",
    "            merged_path = os.path.join(folder_path, f\"{os.path.basename(folder_path)}_merged{suffix or ''}.mp4\")\n",
    "            # Try direct merge first\n",
    "            # If too many files, do batch merge\n",
    "            if len(split_files) > 100:\n",
    "                temp_batch_dir = os.path.join(folder_path, 'batch_merge_temp')\n",
    "                batch_files = batch_merge(split_files, 100, temp_batch_dir)\n",
    "                merged_ok = merge_videos(batch_files, merged_path)\n",
    "                # Clean up batch files\n",
    "                for f, _ in batch_files:\n",
    "                    if os.path.exists(f):\n",
    "                        os.remove(f)\n",
    "                if os.path.exists(temp_batch_dir):\n",
    "                    shutil.rmtree(temp_batch_dir)\n",
    "            else:\n",
    "                merged_ok = merge_videos(split_files, merged_path)\n",
    "            converted_dir = None\n",
    "            use_conversion = False\n",
    "            merged_duration = get_video_duration(merged_path) if merged_ok else 0\n",
    "            sum_original = sum([get_video_duration(f) for f, _ in split_files])\n",
    "            # Sanity check: merged duration should be within 10% of sum of originals\n",
    "            if merged_ok and sum_original > 0:\n",
    "                diff_ratio = abs(merged_duration - sum_original) / sum_original\n",
    "                if diff_ratio > 0.10:\n",
    "                    logging.warning(f\"Merged video duration {merged_duration/3600:.2f}h differs by more than 10% from originals ({sum_original/3600:.2f}h). Will try safe conversion path.\")\n",
    "                    merged_ok = False\n",
    "                    use_conversion = True\n",
    "                    if os.path.exists(merged_path):\n",
    "                        os.remove(merged_path)\n",
    "            # If merged video is more than 3x the sum of originals and >8 hours, treat as failed\n",
    "            if merged_ok and merged_duration > max(8*3600, 3*sum_original):\n",
    "                logging.warning(f\"Merged video duration {merged_duration/3600:.2f}h is much larger than originals ({sum_original/3600:.2f}h). Will try safe conversion path.\")\n",
    "                merged_ok = False\n",
    "                use_conversion = True\n",
    "                if os.path.exists(merged_path):\n",
    "                    os.remove(merged_path)\n",
    "            if not merged_ok:\n",
    "                logging.warning(f\"Direct merge failed or unsafe for part {suffix or 'single'}. Attempting conversion.\")\n",
    "                # Convert all to mp4 in a subfolder\n",
    "                if os.path.basename(folder_path) == 'converted_videos':\n",
    "                    converted_dir = os.path.join(folder_path, 'converted_videos_2')\n",
    "                else:\n",
    "                    converted_dir = os.path.join(folder_path, 'converted_videos')\n",
    "                converted_files = convert_all_videos(split_files, converted_dir)\n",
    "                if not converted_files:\n",
    "                    logging.error(f\"Conversion failed for all videos in part {suffix or 'single'}.\")\n",
    "                    continue\n",
    "                # If too many files, do batch merge after conversion\n",
    "                if len(converted_files) > 100:\n",
    "                    temp_batch_dir = os.path.join(folder_path, 'batch_merge_temp')\n",
    "                    batch_files = batch_merge(converted_files, 100, temp_batch_dir)\n",
    "                    merged_ok = merge_videos(batch_files, merged_path)\n",
    "                    for f, _ in batch_files:\n",
    "                        if os.path.exists(f):\n",
    "                            os.remove(f)\n",
    "                    if os.path.exists(temp_batch_dir):\n",
    "                        shutil.rmtree(temp_batch_dir)\n",
    "                else:\n",
    "                    merged_ok = merge_videos([(f, r) for f, r in converted_files], merged_path)\n",
    "                if not merged_ok:\n",
    "                    logging.error(f\"Failed to merge even after conversion for part {suffix or 'single'}\")\n",
    "                    continue\n",
    "                split_files = [(f, r) for f, r in converted_files]  # For timestamps\n",
    "                # Recalculate durations after conversion\n",
    "                merged_duration = get_video_duration(merged_path)\n",
    "                sum_original = sum([get_video_duration(f) for f, _ in split_files])\n",
    "                # Sanity check again after conversion\n",
    "                if sum_original > 0:\n",
    "                    diff_ratio = abs(merged_duration - sum_original) / sum_original\n",
    "                    if diff_ratio > 0.10:\n",
    "                        logging.error(f\"Merged video after conversion still differs by more than 10% from originals. Skipping part {suffix or 'single'}.\")\n",
    "                        if os.path.exists(merged_path):\n",
    "                            os.remove(merged_path)\n",
    "                        continue\n",
    "            logging.info(f\"Videos merged successfully for part {suffix or 'single'}\")\n",
    "            # Check merged video duration (should be < 11.5h, but check anyway)\n",
    "            duration = get_video_duration(merged_path)\n",
    "            if duration > 41400:\n",
    "                logging.warning(f\"Merged video is too long ({duration/3600:.2f} hours). Skipping upload and cleanup for: {merged_path}\")\n",
    "                continue\n",
    "            timestamps = generate_timestamps(split_files)\n",
    "            description = sanitize_description(\"Tutorial Contents:\\n\\n\" + timestamps)\n",
    "            title = title_base if not suffix else f\"{title_base} {suffix}\"\n",
    "            title = title.strip()\n",
    "            if not title:\n",
    "                title = os.path.basename(folder_path)\n",
    "            title = sanitize_title(title)\n",
    "            logging.info(f\"Uploading with title: '{title}' (length: {len(title)})\")\n",
    "            if not title or not title.strip():\n",
    "                title = os.path.basename(folder_path)[:100]\n",
    "                logging.warning(f\"Title was empty after sanitization, using fallback: '{title}'\")\n",
    "            youtube = get_authenticated_service(client_secrets_file)\n",
    "            video_id = upload_to_youtube(youtube, merged_path, title, description)\n",
    "            if video_id:\n",
    "                logging.info(f\"Upload successful! Video ID: {video_id}\")\n",
    "                # Pass original files to cleanup if conversion was used\n",
    "                orig_files = [f for f, _ in split_files] if use_conversion else None\n",
    "                cleanup_and_save_link(folder_path, video_id, title, merged_path, converted_dir, delete_all=use_conversion, original_files=orig_files)\n",
    "                logging.info(f\"Video URL: https://www.youtube.com/watch?v={video_id}\")\n",
    "            else:\n",
    "                logging.error(f\"Upload failed for part {suffix or 'single'}\")\n",
    "        # Write skipped files summary\n",
    "        if SKIPPED_FILES:\n",
    "            skipped_path = os.path.join(folder_path, 'skipped_files.txt')\n",
    "            with open(skipped_path, 'w', encoding='utf-8') as f:\n",
    "                for path in SKIPPED_FILES:\n",
    "                    f.write(path + '\\n')\n",
    "            logging.info(f\"Skipped files written to {skipped_path}\")\n",
    "        # Log failed conversions and merges\n",
    "        if FAILED_CONVERSIONS:\n",
    "            logging.error(f\"Failed conversions: {FAILED_CONVERSIONS}\")\n",
    "        if FAILED_MERGES:\n",
    "            logging.error(f\"Failed merges: {FAILED_MERGES}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing folder: {str(e)}\")\n",
    "\n",
    "def find_tutorial_folders_2_levels_down(root_folder: str) -> list:\n",
    "    tutorial_folders = []\n",
    "    for company in os.listdir(root_folder):\n",
    "        company_path = os.path.join(root_folder, company)\n",
    "        if os.path.isdir(company_path):\n",
    "            for tutorial in os.listdir(company_path):\n",
    "                tutorial_path = os.path.join(company_path, tutorial)\n",
    "                if os.path.isdir(tutorial_path):\n",
    "                    tutorial_folders.append(tutorial_path)\n",
    "    return tutorial_folders\n",
    "\n",
    "def select_folder_dialog(title=\"Select the software folder\"):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    folder_selected = filedialog.askdirectory(title=title)\n",
    "    root.destroy()\n",
    "    return folder_selected\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        script_dir = os.getcwd()\n",
    "    client_secrets_file = os.path.join(script_dir, \"client_secret.json\")\n",
    "    if not os.path.exists(client_secrets_file):\n",
    "        print(\"Client secrets file not found\")\n",
    "        return\n",
    "    youtube = get_authenticated_service(client_secrets_file)\n",
    "    print(\"YouTube authentication complete.\")\n",
    "    root_folder = select_folder_dialog(\"Select the software folder (2 levels above tutorial)\")\n",
    "    if not root_folder or not os.path.exists(root_folder):\n",
    "        print(\"Path does not exist or was not selected.\")\n",
    "        return\n",
    "    tutorial_folders = find_tutorial_folders_2_levels_down(root_folder)\n",
    "    if not tutorial_folders:\n",
    "        print(\"No tutorial folders found.\")\n",
    "        return\n",
    "    print(f\"Found {len(tutorial_folders)} tutorial folders.\")\n",
    "    for folder in tutorial_folders:\n",
    "        print(f\"Processing: {folder}\")\n",
    "        process_folder(folder, client_secrets_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
