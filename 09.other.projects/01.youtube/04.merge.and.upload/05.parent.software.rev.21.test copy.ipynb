{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e62070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:02:32 - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YouTube authentication complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Addressing Large Hadron Collider Challenges by Machine Learning\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Addressing Large Hadron Collider Challenges by Machine Learning, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Applied Machine Learning In Python\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Applied Machine Learning In Python, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Deep Learning In Computer Vision\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Deep Learning In Computer Vision, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Introduction To Deep Learning\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Introduction To Deep Learning, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Machine Learning\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Machine Learning, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Neural Networks And Deep Learning\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Neural Networks And Deep Learning, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Lynda\\Artificial Intelligence Foundations - Machine Learning\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Lynda\\Artificial Intelligence Foundations - Machine Learning, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Lynda\\Artificial Intelligence Foundations - Neural Networks\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Lynda\\Artificial Intelligence Foundations - Neural Networks, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Lynda\\Machine Learning And AI Foundations Predictive Modeling Strategy At Scale\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Lynda\\Machine Learning And AI Foundations Predictive Modeling Strategy At Scale, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Packt\\Advanced Machine Learning with Spark 2.x\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Packt\\Advanced Machine Learning with Spark 2.x, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Packt\\Packt Hands-On Deep Learning with Caffe2\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Packt\\Packt Hands-On Deep Learning with Caffe2, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Pluralsight\\Creating Machine Learning Models\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Pluralsight\\Creating Machine Learning Models, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Artificial Intelligence Video Creation - Amazing Video Tools\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Artificial Intelligence Video Creation - Amazing Video Tools, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Artificial Intelligence with Machine Learning, Deep Learning\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Artificial Intelligence with Machine Learning, Deep Learning, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Automated Machine Learning - Auto ML, TPOT, H2O, Auto Keras\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Automated Machine Learning - Auto ML, TPOT, H2O, Auto Keras, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\ChatGPT for Data Science and Machine Learning\n",
      "15:02:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\ChatGPT for Data Science and Machine Learning, skipping upload.\n",
      "15:02:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\ChatGPT for Productivity 7 Essential Hacks You Need Now\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 tutorial folders.\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Addressing Large Hadron Collider Challenges by Machine Learning\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Applied Machine Learning In Python\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Deep Learning In Computer Vision\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Introduction To Deep Learning\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Machine Learning\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Coursera\\Neural Networks And Deep Learning\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Lynda\\Artificial Intelligence Foundations - Machine Learning\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Lynda\\Artificial Intelligence Foundations - Neural Networks\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Lynda\\Machine Learning And AI Foundations Predictive Modeling Strategy At Scale\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Packt\\Advanced Machine Learning with Spark 2.x\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Packt\\Packt Hands-On Deep Learning with Caffe2\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Pluralsight\\Creating Machine Learning Models\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Artificial Intelligence Video Creation - Amazing Video Tools\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Artificial Intelligence with Machine Learning, Deep Learning\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Automated Machine Learning - Auto ML, TPOT, H2O, Auto Keras\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\ChatGPT for Data Science and Machine Learning\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\ChatGPT for Productivity 7 Essential Hacks You Need Now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:02:45 - file_cache is only supported with oauth2client<4.0.0\n",
      "15:10:51 - Upload successful! Video ID: Ev4kaPyTz7Y\n",
      "15:10:51 - Video URL: https://www.youtube.com/watch?v=Ev4kaPyTz7Y\n",
      "15:10:51 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Create AI Animated Video Stories with Consistent Characters\n",
      "15:10:51 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Create AI Animated Video Stories with Consistent Characters, skipping upload.\n",
      "15:10:51 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Data Science in Python Unsupervised Learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Create AI Animated Video Stories with Consistent Characters\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Data Science in Python Unsupervised Learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:11:25 - file_cache is only supported with oauth2client<4.0.0\n",
      "15:35:10 - Upload successful! Video ID: 9gvvP23-sEw\n",
      "15:35:13 - Video URL: https://www.youtube.com/watch?v=9gvvP23-sEw\n",
      "15:35:13 - Merged video file not found: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Data Science in Python Unsupervised Learning\\Data Science in Python Unsupervised Learning_merged02.mp4, skipping upload.\n",
      "15:35:13 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Hands-On Python Machine Learning with Real World Projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Hands-On Python Machine Learning with Real World Projects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:35:16 - file_cache is only supported with oauth2client<4.0.0\n",
      "15:42:42 - Upload successful! Video ID: oXowwOkugcg\n",
      "15:42:42 - Video URL: https://www.youtube.com/watch?v=oXowwOkugcg\n",
      "15:42:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Healthcare NLP for Data Scientists\n",
      "15:42:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Healthcare NLP for Data Scientists, skipping upload.\n",
      "15:42:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Image Illustration with AI\n",
      "15:42:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Image Illustration with AI, skipping upload.\n",
      "15:42:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Learn Data Science Skills Python, Pandas, Machine Learning\n",
      "15:42:42 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Learn Data Science Skills Python, Pandas, Machine Learning, skipping upload.\n",
      "15:42:42 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Learn Python Programming with Chatgpt\n",
      "15:42:43 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Learn Python Programming with Chatgpt, skipping upload.\n",
      "15:42:43 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Linear Algebra Mastery Elevate Your Machine Learning Skills\n",
      "15:42:43 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Linear Algebra Mastery Elevate Your Machine Learning Skills, skipping upload.\n",
      "15:42:43 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Machine Learning, Data Science and Generative AI with Python\n",
      "15:42:43 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Machine Learning, Data Science and Generative AI with Python, skipping upload.\n",
      "15:42:43 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Master Faceless YouTube Automation with AI, ChatGPT & Canva!\n",
      "15:42:43 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Master Faceless YouTube Automation with AI, ChatGPT & Canva!, skipping upload.\n",
      "15:42:43 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\SelfGuided Learning with ChatGPT Learn Faster with AI\n",
      "15:42:43 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\SelfGuided Learning with ChatGPT Learn Faster with AI, skipping upload.\n",
      "15:42:43 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Web calculators with Machine Learning models in Python\n",
      "15:42:43 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Web calculators with Machine Learning models in Python, skipping upload.\n",
      "15:42:43 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\xOther\\Algorithms for Data Science, Python, AI & Machine Learning\n",
      "15:42:43 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\xOther\\Algorithms for Data Science, Python, AI & Machine Learning, skipping upload.\n",
      "15:42:43 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\xOther\\Automated Machine Learning in Action, Video Edition\n",
      "15:42:43 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\xOther\\Automated Machine Learning in Action, Video Edition, skipping upload.\n",
      "15:42:43 - Processing folder: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\xOther\\Machine Learning Engineering in Action, Video Edition\n",
      "15:42:43 - YouTube link file already exists for //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\xOther\\Machine Learning Engineering in Action, Video Edition, skipping upload.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Healthcare NLP for Data Scientists\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Image Illustration with AI\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Learn Data Science Skills Python, Pandas, Machine Learning\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Learn Python Programming with Chatgpt\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Linear Algebra Mastery Elevate Your Machine Learning Skills\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Machine Learning, Data Science and Generative AI with Python\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Master Faceless YouTube Automation with AI, ChatGPT & Canva!\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\SelfGuided Learning with ChatGPT Learn Faster with AI\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\Udemy\\Web calculators with Machine Learning models in Python\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\xOther\\Algorithms for Data Science, Python, AI & Machine Learning\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\xOther\\Automated Machine Learning in Action, Video Edition\n",
      "Processing: //fileserver2/Head Office Server/Projects Control (PC)/10 Backup/05 Tutorials/Topics/Machine Learning\\xOther\\Machine Learning Engineering in Action, Video Edition\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import ffmpeg\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import ssl\n",
    "import string\n",
    "import re\n",
    "import tempfile\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler('video_processing.log', encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "TOKEN_FILE = \"token.json\"\n",
    "SCOPES = [\"https://www.googleapis.com/auth/youtube.upload\"]\n",
    "\n",
    "os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
    "os.environ['PYTHONHTTPSVERIFY'] = '0'\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Add global lists to track failed conversions and merges\n",
    "FAILED_CONVERSIONS = []\n",
    "FAILED_MERGES = []\n",
    "SKIPPED_FILES = []\n",
    "\n",
    "def get_authenticated_service(client_secrets_file: str):\n",
    "    creds = None\n",
    "    if os.path.exists(TOKEN_FILE):\n",
    "        creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(client_secrets_file, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open(TOKEN_FILE, 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return build('youtube', 'v3', credentials=creds)\n",
    "\n",
    "def get_structured_title(input_path: str) -> str:\n",
    "    try:\n",
    "        path = Path(input_path)\n",
    "        parts = list(path.parts)[-4:]\n",
    "        return ' - '.join(parts)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in get_structured_title: {str(e)}\")\n",
    "        return os.path.basename(input_path)\n",
    "\n",
    "def collect_videos(folder_path: str) -> List[Tuple[str, str]]:\n",
    "    video_files = []\n",
    "    extensions = ('*.mp4', '*.avi', '*.mkv', '*.mov', '*.flv', '*.rmvb')\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # Skip any 'converted_videos' subfolder\n",
    "        if 'converted_videos' in root.split(os.sep):\n",
    "            continue\n",
    "        for ext in extensions:\n",
    "            for file in glob.glob(os.path.join(root, ext)):\n",
    "                rel_path = os.path.relpath(file, folder_path)\n",
    "                video_files.append((file, rel_path))\n",
    "    return sorted(video_files)\n",
    "\n",
    "def merge_videos(video_files: List[Tuple[str, str]], output_path: str) -> bool:\n",
    "    try:\n",
    "        valid_files = []\n",
    "        file_list_path = None\n",
    "        with tempfile.NamedTemporaryFile('w', delete=False, suffix='.txt', encoding='utf-8') as tmpfile:\n",
    "            for full_path, _ in video_files:\n",
    "                if not os.path.exists(full_path):\n",
    "                    logging.error(f\"File does not exist, skipping: {full_path}\")\n",
    "                    SKIPPED_FILES.append(full_path)\n",
    "                    continue\n",
    "                if get_video_duration(full_path) <= 0:\n",
    "                    logging.error(f\"File is not a valid video or is corrupt, skipping: {full_path}\")\n",
    "                    SKIPPED_FILES.append(full_path)\n",
    "                    continue\n",
    "                abs_path = os.path.abspath(full_path).replace('\\\\', '/')\n",
    "                abs_path = abs_path.replace(\"'\", \"'\\\\''\")\n",
    "                tmpfile.write(f\"file '{abs_path}'\\n\")\n",
    "                valid_files.append(full_path)\n",
    "            file_list_path = tmpfile.name\n",
    "        if not valid_files:\n",
    "            logging.error(f\"No valid files to merge for output: {output_path}\")\n",
    "            FAILED_MERGES.append(output_path)\n",
    "            return False\n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-f', 'concat',\n",
    "            '-safe', '0',\n",
    "            '-i', file_list_path,\n",
    "            '-c', 'copy',\n",
    "            output_path,\n",
    "            '-y'\n",
    "        ]\n",
    "        process = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')\n",
    "        if process.returncode != 0:\n",
    "            logging.error(f\"Error merging videos: {process.stderr}\")\n",
    "            FAILED_MERGES.append(output_path)\n",
    "            # Log the list of files in this batch for debugging\n",
    "            logging.error(f\"Files in failed batch merge for {output_path}: {valid_files}\")\n",
    "        return process.returncode == 0\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error merging videos: {str(e)}\")\n",
    "        FAILED_MERGES.append(output_path)\n",
    "        return False\n",
    "    finally:\n",
    "        if 'file_list_path' in locals() and file_list_path and os.path.exists(file_list_path):\n",
    "            os.remove(file_list_path)\n",
    "\n",
    "def convert_video(input_path: str, output_path: str) -> bool:\n",
    "    try:\n",
    "        cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', input_path,\n",
    "            '-vf', 'scale=-2:720',\n",
    "            '-r', '30',\n",
    "            '-c:v', 'libx264',\n",
    "            '-preset', 'fast',\n",
    "            '-crf', '23',\n",
    "            '-c:a', 'aac',\n",
    "            '-b:a', '128k',\n",
    "            '-y',\n",
    "            output_path\n",
    "        ]\n",
    "        process = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')\n",
    "        if process.returncode != 0:\n",
    "            logging.error(f\"Error converting {input_path}: {process.stderr}\")\n",
    "            FAILED_CONVERSIONS.append(input_path)\n",
    "        return process.returncode == 0\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception converting {input_path}: {str(e)}\")\n",
    "        FAILED_CONVERSIONS.append(input_path)\n",
    "        return False\n",
    "\n",
    "def convert_all_videos(video_files: List[Tuple[str, str]], converted_dir: str) -> List[Tuple[str, str]]:\n",
    "    os.makedirs(converted_dir, exist_ok=True)\n",
    "    converted_files = []\n",
    "    for full_path, rel_path in video_files:\n",
    "        base_name = os.path.splitext(rel_path)[0] + '.mp4'\n",
    "        out_path = os.path.join(converted_dir, base_name)\n",
    "        out_dir = os.path.dirname(out_path)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        if convert_video(full_path, out_path):\n",
    "            converted_files.append((out_path, rel_path))\n",
    "        else:\n",
    "            logging.error(f\"Failed to convert {full_path}\")\n",
    "    return converted_files\n",
    "\n",
    "def sanitize_description(desc: str) -> str:\n",
    "    \"\"\"Remove non-printable characters and truncate to 5000 chars for YouTube description.\"\"\"\n",
    "    desc = re.sub(r'[^\\x09\\x0A\\x0D\\x20-\\x7E\\u00A0-\\uD7FF\\uE000-\\uFFFD]', '', desc)\n",
    "    return desc[:5000]\n",
    "\n",
    "def generate_timestamps(video_files: List[Tuple[str, str]]) -> str:\n",
    "    timestamps = []\n",
    "    current_time = 0\n",
    "    for full_path, rel_path in video_files:\n",
    "        hours = int(current_time // 3600)\n",
    "        minutes = int((current_time % 3600) // 60)\n",
    "        seconds = int(current_time % 60)\n",
    "        timestamp = f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "        video_name = os.path.splitext(os.path.basename(rel_path))[0]\n",
    "        timestamps.append(f\"{timestamp} - {video_name}\")\n",
    "        try:\n",
    "            cmd = [\n",
    "                'ffprobe', '-v', 'error', '-show_entries', 'format=duration',\n",
    "                '-of', 'default=noprint_wrappers=1:nokey=1', full_path\n",
    "            ]\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            if result.returncode == 0 and result.stdout.strip():\n",
    "                duration = float(result.stdout.strip())\n",
    "                current_time += duration\n",
    "            else:\n",
    "                logging.error(f\"ffprobe error for {full_path}: {result.stderr.strip()}\")\n",
    "                current_time += 0\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Exception running ffprobe for {full_path}: {str(e)}\")\n",
    "            current_time += 0\n",
    "    return '\\n'.join(timestamps)\n",
    "\n",
    "def upload_to_youtube(youtube, video_path: str, title: str, description: str) -> Optional[str]:\n",
    "    try:\n",
    "        body = {\n",
    "            'snippet': {\n",
    "                'title': title,\n",
    "                'description': description,\n",
    "                'tags': ['tutorial', 'education']\n",
    "            },\n",
    "            'status': {\n",
    "                'privacyStatus': 'unlisted',\n",
    "                'selfDeclaredMadeForKids': False\n",
    "            }\n",
    "        }\n",
    "        insert_request = youtube.videos().insert(\n",
    "            part=','.join(body.keys()),\n",
    "            body=body,\n",
    "            media_body=MediaFileUpload(video_path, chunksize=-1, resumable=True)\n",
    "        )\n",
    "        response = None\n",
    "        while response is None:\n",
    "            status, response = insert_request.next_chunk()\n",
    "            if status:\n",
    "                logging.info(f\"Upload {int(status.progress() * 100)}% complete\")\n",
    "        return response['id']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error uploading to YouTube: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def cleanup_and_save_link(folder_path: str, video_id: str, title: str, merged_path: str, converted_dir: Optional[str] = None, delete_all: bool = False, original_files: Optional[list] = None):\n",
    "    link_file = os.path.join(folder_path, \"youtube link.txt\")\n",
    "    with open(link_file, 'w') as f:\n",
    "        f.write(f\"Title: {title}\\n\")\n",
    "        f.write(f\"URL: https://www.youtube.com/watch?v={video_id}\\n\")\n",
    "        f.write(f\"Uploaded: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    # Delete merged video\n",
    "    if os.path.exists(merged_path):\n",
    "        try:\n",
    "            os.remove(merged_path)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to delete merged video: {merged_path}: {str(e)}\")\n",
    "    # Delete all video files in the top-level tutorial folder (except the link file)\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if item_path == link_file:\n",
    "            continue\n",
    "        if os.path.isfile(item_path) and item_path.lower().endswith((\".mp4\", \".flv\", \".avi\", \".mkv\", \".mov\", \".rmvb\")):\n",
    "            try:\n",
    "                os.remove(item_path)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to delete video file: {item_path}: {str(e)}\")\n",
    "        elif os.path.isdir(item_path):\n",
    "            try:\n",
    "                shutil.rmtree(item_path)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to delete folder: {item_path}: {str(e)}\")\n",
    "    # Remove converted_videos folder if present\n",
    "    if converted_dir and os.path.exists(converted_dir):\n",
    "        try:\n",
    "            shutil.rmtree(converted_dir)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to delete converted_videos: {converted_dir}: {str(e)}\")\n",
    "    # If delete_all is True, remove all original video files in all subfolders as well\n",
    "    if delete_all:\n",
    "        # Remove all original video files (not just converted) in all subfolders\n",
    "        if original_files:\n",
    "            for orig_file in original_files:\n",
    "                if os.path.exists(orig_file):\n",
    "                    try:\n",
    "                        os.remove(orig_file)\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Failed to delete original video file: {orig_file}: {str(e)}\")\n",
    "        else:\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    if file.endswith((\".mp4\", \".avi\", \".mkv\", \".mov\", \".flv\", \".rmvb\")):\n",
    "                        try:\n",
    "                            os.remove(os.path.join(root, file))\n",
    "                        except Exception as e:\n",
    "                            logging.error(f\"Failed to delete {file}: {str(e)}\")\n",
    "                for dir in dirs:\n",
    "                    dir_path = os.path.join(root, dir)\n",
    "                    if dir_path != converted_dir and os.path.exists(dir_path):\n",
    "                        try:\n",
    "                            shutil.rmtree(dir_path)\n",
    "                        except Exception as e:\n",
    "                            logging.error(f\"Failed to delete directory {dir_path}: {str(e)}\")\n",
    "\n",
    "def get_video_duration(video_path: str) -> float:\n",
    "    try:\n",
    "        probe = ffmpeg.probe(video_path)\n",
    "        for stream in probe['streams']:\n",
    "            if 'duration' in stream:\n",
    "                return float(stream['duration'])\n",
    "        return float(probe['format']['duration'])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error getting duration for {video_path}: {str(e)}\")\n",
    "        SKIPPED_FILES.append(video_path)\n",
    "        return 0.0\n",
    "\n",
    "def sanitize_title(title):\n",
    "    # Remove non-printable characters\n",
    "    printable = set(string.printable)\n",
    "    title = ''.join(filter(lambda x: x in printable, title))\n",
    "    # Truncate to 100 chars\n",
    "    return title[:100]\n",
    "\n",
    "def split_videos_by_duration(video_files: List[Tuple[str, str]], durations: List[float], max_duration: float = 41400) -> List[Tuple[List[Tuple[str, str]], List[float], str]]:\n",
    "    \"\"\"\n",
    "    Splits the list of video files into as many parts as needed so that each part's total duration is <= max_duration (default 11.5 hours).\n",
    "    Returns a list of tuples: (split_files, split_durations, suffix)\n",
    "    \"\"\"\n",
    "    splits = []\n",
    "    part = []\n",
    "    part_durations = []\n",
    "    part_total = 0.0\n",
    "    part_idx = 1\n",
    "    for (file, rel), dur in zip(video_files, durations):\n",
    "        if part_total + dur > max_duration and part:\n",
    "            splits.append((part, part_durations, f\"{part_idx:02d}\"))\n",
    "            part = []\n",
    "            part_durations = []\n",
    "            part_total = 0.0\n",
    "            part_idx += 1\n",
    "        part.append((file, rel))\n",
    "        part_durations.append(dur)\n",
    "        part_total += dur\n",
    "    if part:\n",
    "        splits.append((part, part_durations, f\"{part_idx:02d}\"))\n",
    "    return splits\n",
    "\n",
    "def batch_merge(video_files: List[Tuple[str, str]], batch_size: int, temp_dir: str) -> List[Tuple[str, str]]:\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    batch_files = []\n",
    "    for i in range(0, len(video_files), batch_size):\n",
    "        batch = video_files[i:i+batch_size]\n",
    "        batch_path = os.path.join(temp_dir, f\"batch_{i//batch_size:03d}.mp4\")\n",
    "        if merge_videos(batch, batch_path):\n",
    "            batch_files.append((batch_path, f\"batch_{i//batch_size:03d}.mp4\"))\n",
    "        else:\n",
    "            logging.error(f\"Batch merge failed for {batch_path}\")\n",
    "            FAILED_MERGES.append(batch_path)\n",
    "    return batch_files\n",
    "\n",
    "def process_folder(folder_path: str, client_secrets_file: str):\n",
    "    try:\n",
    "        if os.path.basename(folder_path) == 'converted_videos':\n",
    "            logging.error(\"Refusing to process a folder named 'converted_videos' to avoid recursion.\")\n",
    "            return\n",
    "        logging.info(f\"Processing folder: {folder_path}\")\n",
    "        # REV 16: Check for existing merged video and youtube link\n",
    "        link_file = os.path.join(folder_path, \"youtube link.txt\")\n",
    "        merged_videos = [f for f in os.listdir(folder_path) if f.endswith('.mp4') and '_merged' in f]\n",
    "        if os.path.exists(link_file):\n",
    "            logging.info(f\"YouTube link file already exists for {folder_path}, skipping upload.\")\n",
    "            return\n",
    "        if merged_videos:\n",
    "            # If multiple merged videos, upload each (for split parts)\n",
    "            merged_videos = sorted(merged_videos)\n",
    "            for merged_name in merged_videos:\n",
    "                merged_path = os.path.join(folder_path, merged_name)\n",
    "                if not os.path.exists(merged_path):\n",
    "                    logging.warning(f\"Merged video file not found: {merged_path}, skipping upload.\")\n",
    "                    continue\n",
    "                # Use structured title (last 4 folders separated by dashes)\n",
    "                title = get_structured_title(folder_path)\n",
    "                if not title or not title.strip():\n",
    "                    title = os.path.splitext(merged_name)[0]\n",
    "                # If there are multiple merged videos, add suffix\n",
    "                if len(merged_videos) > 1:\n",
    "                    suffix = os.path.splitext(merged_name)[0].replace(os.path.basename(folder_path), '').replace('_merged', '').strip()\n",
    "                    if suffix:\n",
    "                        title = f\"{title} {suffix}\"\n",
    "                title = sanitize_title(title)\n",
    "                # Try to generate timestamps from original videos if they exist\n",
    "                video_files = collect_videos(folder_path)\n",
    "                if video_files:\n",
    "                    timestamps = generate_timestamps(video_files)\n",
    "                    description = sanitize_description(\"Tutorial Contents:\\n\\n\" + timestamps)\n",
    "                else:\n",
    "                    description = sanitize_description(\"Tutorial video upload.\")\n",
    "                youtube = get_authenticated_service(client_secrets_file)\n",
    "                video_id = upload_to_youtube(youtube, merged_path, title, description)\n",
    "                if video_id:\n",
    "                    logging.info(f\"Upload successful! Video ID: {video_id}\")\n",
    "                    # Clean up and save link as in normal flow\n",
    "                    cleanup_and_save_link(folder_path, video_id, title, merged_path)\n",
    "                    logging.info(f\"Video URL: https://www.youtube.com/watch?v={video_id}\")\n",
    "                else:\n",
    "                    logging.error(f\"Upload failed for merged video: {merged_name}\")\n",
    "            return\n",
    "        video_files = collect_videos(folder_path)\n",
    "        if not video_files:\n",
    "            logging.error(\"No video files found\")\n",
    "            return\n",
    "        logging.info(f\"Found {len(video_files)} videos\")\n",
    "        # Calculate total duration\n",
    "        total_duration = 0\n",
    "        durations = []\n",
    "        for file, _ in video_files:\n",
    "            d = get_video_duration(file)\n",
    "            if d == 0.0:\n",
    "                logging.error(f\"Skipping unreadable/corrupt file: {file}\")\n",
    "                continue\n",
    "            durations.append(d)\n",
    "            total_duration += d\n",
    "        if not durations:\n",
    "            logging.error(\"No valid video files after filtering corrupt/unreadable files.\")\n",
    "            return\n",
    "        logging.info(f\"Total duration: {total_duration/3600:.2f} hours\")\n",
    "        title_base = get_structured_title(folder_path)\n",
    "        if not title_base or not title_base.strip():\n",
    "            title_base = os.path.basename(folder_path)\n",
    "        logging.info(f\"Generated title: {title_base}\")\n",
    "        # Split into as many parts as needed so each is <= 11.5 hours\n",
    "        if total_duration > 41400 and len(video_files) > 1:\n",
    "            splits = split_videos_by_duration(video_files, durations, max_duration=41400)\n",
    "        else:\n",
    "            splits = [(video_files, durations, None)]\n",
    "        for idx, (split_files, split_durations, suffix) in enumerate(splits):\n",
    "            merged_path = os.path.join(folder_path, f\"{os.path.basename(folder_path)}_merged{suffix or ''}.mp4\")\n",
    "            # Try direct merge first\n",
    "            # If too many files, do batch merge\n",
    "            if len(split_files) > 100:\n",
    "                temp_batch_dir = os.path.join(folder_path, 'batch_merge_temp')\n",
    "                batch_files = batch_merge(split_files, 100, temp_batch_dir)\n",
    "                merged_ok = merge_videos(batch_files, merged_path)\n",
    "                # Clean up batch files\n",
    "                for f, _ in batch_files:\n",
    "                    if os.path.exists(f):\n",
    "                        os.remove(f)\n",
    "                if os.path.exists(temp_batch_dir):\n",
    "                    shutil.rmtree(temp_batch_dir)\n",
    "            else:\n",
    "                merged_ok = merge_videos(split_files, merged_path)\n",
    "            converted_dir = None\n",
    "            use_conversion = False\n",
    "            merged_duration = get_video_duration(merged_path) if merged_ok else 0\n",
    "            sum_original = sum([get_video_duration(f) for f, _ in split_files])\n",
    "            # Sanity check: merged duration should be within 10% of sum of originals\n",
    "            if merged_ok and sum_original > 0:\n",
    "                diff_ratio = abs(merged_duration - sum_original) / sum_original\n",
    "                if diff_ratio > 0.10:\n",
    "                    logging.warning(f\"Merged video duration {merged_duration/3600:.2f}h differs by more than 10% from originals ({sum_original/3600:.2f}h). Will try safe conversion path.\")\n",
    "                    merged_ok = False\n",
    "                    use_conversion = True\n",
    "                    if os.path.exists(merged_path):\n",
    "                        os.remove(merged_path)\n",
    "            # If merged video is more than 3x the sum of originals and >8 hours, treat as failed\n",
    "            if merged_ok and merged_duration > max(8*3600, 3*sum_original):\n",
    "                logging.warning(f\"Merged video duration {merged_duration/3600:.2f}h is much larger than originals ({sum_original/3600:.2f}h). Will try safe conversion path.\")\n",
    "                merged_ok = False\n",
    "                use_conversion = True\n",
    "                if os.path.exists(merged_path):\n",
    "                    os.remove(merged_path)\n",
    "            if not merged_ok:\n",
    "                logging.warning(f\"Direct merge failed or unsafe for part {suffix or 'single'}. Attempting conversion.\")\n",
    "                # Convert all to mp4 in a subfolder\n",
    "                if os.path.basename(folder_path) == 'converted_videos':\n",
    "                    converted_dir = os.path.join(folder_path, 'converted_videos_2')\n",
    "                else:\n",
    "                    converted_dir = os.path.join(folder_path, 'converted_videos')\n",
    "                converted_files = convert_all_videos(split_files, converted_dir)\n",
    "                if not converted_files:\n",
    "                    logging.error(f\"Conversion failed for all videos in part {suffix or 'single'}.\")\n",
    "                    continue\n",
    "                # If too many files, do batch merge after conversion\n",
    "                if len(converted_files) > 100:\n",
    "                    temp_batch_dir = os.path.join(folder_path, 'batch_merge_temp')\n",
    "                    batch_files = batch_merge(converted_files, 100, temp_batch_dir)\n",
    "                    merged_ok = merge_videos(batch_files, merged_path)\n",
    "                    for f, _ in batch_files:\n",
    "                        if os.path.exists(f):\n",
    "                            os.remove(f)\n",
    "                    if os.path.exists(temp_batch_dir):\n",
    "                        shutil.rmtree(temp_batch_dir)\n",
    "                else:\n",
    "                    merged_ok = merge_videos([(f, r) for f, r in converted_files], merged_path)\n",
    "                if not merged_ok:\n",
    "                    logging.error(f\"Failed to merge even after conversion for part {suffix or 'single'}\")\n",
    "                    continue\n",
    "                split_files = [(f, r) for f, r in converted_files]  # For timestamps\n",
    "                # Recalculate durations after conversion\n",
    "                merged_duration = get_video_duration(merged_path)\n",
    "                sum_original = sum([get_video_duration(f) for f, _ in split_files])\n",
    "                # Sanity check again after conversion\n",
    "                if sum_original > 0:\n",
    "                    diff_ratio = abs(merged_duration - sum_original) / sum_original\n",
    "                    if diff_ratio > 0.10:\n",
    "                        logging.error(f\"Merged video after conversion still differs by more than 10% from originals. Skipping part {suffix or 'single'}.\")\n",
    "                        if os.path.exists(merged_path):\n",
    "                            os.remove(merged_path)\n",
    "                        continue\n",
    "            logging.info(f\"Videos merged successfully for part {suffix or 'single'}\")\n",
    "            # Check merged video duration (should be < 11.5h, but check anyway)\n",
    "            duration = get_video_duration(merged_path)\n",
    "            if duration > 41400:\n",
    "                logging.warning(f\"Merged video is too long ({duration/3600:.2f} hours). Skipping upload and cleanup for: {merged_path}\")\n",
    "                continue\n",
    "            timestamps = generate_timestamps(split_files)\n",
    "            description = sanitize_description(\"Tutorial Contents:\\n\\n\" + timestamps)\n",
    "            title = title_base if not suffix else f\"{title_base} {suffix}\"\n",
    "            title = title.strip()\n",
    "            if not title:\n",
    "                title = os.path.basename(folder_path)\n",
    "            title = sanitize_title(title)\n",
    "            logging.info(f\"Uploading with title: '{title}' (length: {len(title)})\")\n",
    "            if not title or not title.strip():\n",
    "                title = os.path.basename(folder_path)[:100]\n",
    "                logging.warning(f\"Title was empty after sanitization, using fallback: '{title}'\")\n",
    "            youtube = get_authenticated_service(client_secrets_file)\n",
    "            video_id = upload_to_youtube(youtube, merged_path, title, description)\n",
    "            if video_id:\n",
    "                logging.info(f\"Upload successful! Video ID: {video_id}\")\n",
    "                # Pass original files to cleanup if conversion was used\n",
    "                orig_files = [f for f, _ in split_files] if use_conversion else None\n",
    "                cleanup_and_save_link(folder_path, video_id, title, merged_path, converted_dir, delete_all=use_conversion, original_files=orig_files)\n",
    "                logging.info(f\"Video URL: https://www.youtube.com/watch?v={video_id}\")\n",
    "            else:\n",
    "                logging.error(f\"Upload failed for part {suffix or 'single'}\")\n",
    "        # Write skipped files summary\n",
    "        if SKIPPED_FILES:\n",
    "            skipped_path = os.path.join(folder_path, 'skipped_files.txt')\n",
    "            with open(skipped_path, 'w', encoding='utf-8') as f:\n",
    "                for path in SKIPPED_FILES:\n",
    "                    f.write(path + '\\n')\n",
    "            logging.info(f\"Skipped files written to {skipped_path}\")\n",
    "        # Log failed conversions and merges\n",
    "        if FAILED_CONVERSIONS:\n",
    "            logging.error(f\"Failed conversions: {FAILED_CONVERSIONS}\")\n",
    "        if FAILED_MERGES:\n",
    "            logging.error(f\"Failed merges: {FAILED_MERGES}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing folder: {str(e)}\")\n",
    "\n",
    "def find_tutorial_folders_2_levels_down(root_folder: str) -> list:\n",
    "    tutorial_folders = []\n",
    "    for company in os.listdir(root_folder):\n",
    "        company_path = os.path.join(root_folder, company)\n",
    "        if os.path.isdir(company_path):\n",
    "            for tutorial in os.listdir(company_path):\n",
    "                tutorial_path = os.path.join(company_path, tutorial)\n",
    "                if os.path.isdir(tutorial_path):\n",
    "                    tutorial_folders.append(tutorial_path)\n",
    "    return tutorial_folders\n",
    "\n",
    "def select_folder_dialog(title=\"Select the software folder\"):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    folder_selected = filedialog.askdirectory(title=title)\n",
    "    root.destroy()\n",
    "    return folder_selected\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        script_dir = os.getcwd()\n",
    "    client_secrets_file = os.path.join(script_dir, \"client_secret.json\")\n",
    "    if not os.path.exists(client_secrets_file):\n",
    "        print(\"Client secrets file not found\")\n",
    "        return\n",
    "    youtube = get_authenticated_service(client_secrets_file)\n",
    "    print(\"YouTube authentication complete.\")\n",
    "    root_folder = select_folder_dialog(\"Select the software folder (2 levels above tutorial)\")\n",
    "    if not root_folder or not os.path.exists(root_folder):\n",
    "        print(\"Path does not exist or was not selected.\")\n",
    "        return\n",
    "    tutorial_folders = find_tutorial_folders_2_levels_down(root_folder)\n",
    "    if not tutorial_folders:\n",
    "        print(\"No tutorial folders found.\")\n",
    "        return\n",
    "    print(f\"Found {len(tutorial_folders)} tutorial folders.\")\n",
    "    for folder in tutorial_folders:\n",
    "        print(f\"Processing: {folder}\")\n",
    "        process_folder(folder, client_secrets_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
