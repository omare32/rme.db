{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.graph_objs as go\n",
    "import dash_bootstrap_components as dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Read data from Excel files\n",
    "staff_data = pd.read_excel('staff.xlsx')  # Replace 'path_to_staff.xlsx' with the actual path\n",
    "types_data = pd.read_excel('types.xlsx')  # Replace 'path_to_types.xlsx' with the actual path\n",
    "\n",
    "# Merge the data based on the 'Project' column\n",
    "merged_data = staff_data.merge(types_data, on='Project', how='inner')\n",
    "\n",
    "# Calculate maximum job number for each job in a month for each project\n",
    "max_job_numbers = merged_data.groupby(['Type', 'Job', 'Project']).agg({'Month': 'count'}).reset_index()\n",
    "max_job_numbers = max_job_numbers.rename(columns={'Month': 'Number_of_Jobs'})\n",
    "\n",
    "# Calculate average maximum job number rounded down\n",
    "average_max_job_number = math.floor(max_job_numbers['Number_of_Jobs'].mean())\n",
    "\n",
    "# Calculate average start and end months for each job title in a project\n",
    "avg_start_end = staff_data.groupby(['Job', 'Project']).agg({'Month': ['min', 'max']}).reset_index()\n",
    "avg_start_end.columns = ['Job', 'Project', 'Start_Month', 'End_Month']\n",
    "\n",
    "# Create the new project using the calculated averages\n",
    "new_project = {\n",
    "    'Job_Title': [],\n",
    "    'Start_Month': [],\n",
    "    'End_Month': [],\n",
    "    'Number_of_Jobs': []\n",
    "}\n",
    "\n",
    "for index, row in avg_start_end.iterrows():\n",
    "    new_project['Job_Title'].append(row['Job'])\n",
    "    new_project['Start_Month'].append(row['Start_Month'].month)\n",
    "    new_project['End_Month'].append(row['End_Month'].month)\n",
    "    new_project['Number_of_Jobs'].append(average_max_job_number)  # Using the calculated average max job number\n",
    "\n",
    "\n",
    "# Create final_df DataFrame\n",
    "final_df = pd.DataFrame(new_project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Job    Project      Month        Type\n",
      "0              سائق لودر  Beni Suef 2015-10-01  Industrial\n",
      "1             Storekeepe  Beni Suef 2015-10-01  Industrial\n",
      "2  Survyour Section Head  Beni Suef 2015-10-01  Industrial\n",
      "3                Foreman  Beni Suef 2015-10-01  Industrial\n",
      "4                Foreman  Beni Suef 2015-10-01  Industrial\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from Excel files\n",
    "staff_data = pd.read_excel('staff.xlsx')  # Replace 'path_to_staff.xlsx' with the actual path\n",
    "types_data = pd.read_excel('types.xlsx')  # Replace 'path_to_types.xlsx' with the actual path\n",
    "\n",
    "# Merge the data based on the 'Project' column\n",
    "final_df = pd.merge(staff_data, types_data, on='Project')\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Job    Project      Month\n",
      "0                  سائق لودر  Beni Suef 2015-10-01\n",
      "1              Site Engineer        Tb2 2015-10-01\n",
      "2          Project Manager .        Tb2 2015-10-01\n",
      "3              Site Engineer        Tb2 2015-10-01\n",
      "4  Technical Office Engineer        Tb2 2015-10-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the staff data from 'staff.xlsx'\n",
    "staff_data = pd.read_excel('staff.xlsx')\n",
    "\n",
    "# Display the first few rows to ensure the data is loaded correctly\n",
    "print(staff_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average max job number: 20\n",
      "                  Project                    Job  Peak_Number  \\\n",
      "0  10th of Ramadan Bridge  Blacksmith Supervisor            3   \n",
      "1  10th of Ramadan Bridge   Carpenter Supervisor            2   \n",
      "2  10th of Ramadan Bridge   Construction Foreman            3   \n",
      "3  10th of Ramadan Bridge   Construction Manager            4   \n",
      "4  10th of Ramadan Bridge    Document Controller            2   \n",
      "\n",
      "  Average_Start_Month Average_End_Month  \n",
      "0          2020-06-01        2020-08-01  \n",
      "1          2020-06-01        2020-07-01  \n",
      "2          2020-05-01        2020-07-01  \n",
      "3          2020-05-01        2020-08-01  \n",
      "4          2020-06-01        2020-07-01  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'Month' column to datetime if it's not already in datetime format\n",
    "staff_data['Month'] = pd.to_datetime(staff_data['Month'])\n",
    "\n",
    "# Group by 'Project' and 'Job' to calculate the peak number of employees and average start/end months\n",
    "grouped_data = staff_data.groupby(['Project', 'Job']).agg(\n",
    "    Peak_Number=('Job', 'count'),\n",
    "    Average_Start_Month=('Month', 'min'),\n",
    "    Average_End_Month=('Month', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the average peak number for each job across all projects\n",
    "average_max_job_number = grouped_data['Peak_Number'].mean()\n",
    "\n",
    "# Round down the average max job number to the nearest whole number\n",
    "average_max_job_number = int(average_max_job_number)\n",
    "\n",
    "# Display the results\n",
    "print(\"Average max job number:\", average_max_job_number)\n",
    "print(grouped_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Project'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9112\\656848078.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Project'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Now 'final_df' should contain the 'Type' column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0muser_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter the type: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_merge_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1287\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1288\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1289\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m                         \u001b[1;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1844\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Project'"
     ]
    }
   ],
   "source": [
    "final_df = pd.merge(final_df, types_data, on='Project')\n",
    "\n",
    "# Now 'final_df' should contain the 'Type' column\n",
    "user_type = input(\"Enter the type: \")\n",
    "filtered_df = final_df[final_df['Type'] == user_type]\n",
    "# Proceed with calculating start and end months for the new deployment plan using filtered_df\n",
    "\n",
    "\n",
    "# Calculate the start and end months for the new deployment plan:\n",
    "number_of_months = int(input(\"Enter the number of months: \"))  # Assuming user inputs the number of months\n",
    "\n",
    "# Calculate start and end months\n",
    "start_month = filtered_df['Start_Month'].mean()  # Get the average start month\n",
    "end_month = start_month + number_of_months  # Calculate the end month\n",
    "\n",
    "# Ensure the end month does not exceed the maximum end month in the dataset\n",
    "max_end_month = filtered_df['End_Month'].max()\n",
    "if end_month > max_end_month:\n",
    "    end_month = max_end_month\n",
    "\n",
    "#Create the new deployment plan:\n",
    "new_deployment_plan = {\n",
    "    'Type': user_type,\n",
    "    'Start_Month': int(start_month),\n",
    "    'End_Month': int(end_month),\n",
    "    'Number_of_Jobs': filtered_df['Number_of_Jobs'].iloc[0]  # Assuming the number of jobs remains constant\n",
    "}\n",
    "\n",
    "print(\"New Deployment Plan:\")\n",
    "print(new_deployment_plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "df = pd.read_excel(\"staff.xlsx\")\n",
    "\n",
    "# Read the project types\n",
    "df_types = pd.read_excel(\"types.xlsx\")\n",
    "\n",
    "# Create dropdown menu options from unique project names\n",
    "project_options = [{'label': project, 'value': project} for project in df['Project'].unique()]\n",
    "\n",
    "# Create dropdown menu options for project types\n",
    "type_options = [{'label': project_type, 'value': project_type} for project_type in df_types['Type'].unique()]\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Deployment Plan\"),\n",
    "    dbc.Button(\"New Project\", id=\"open\", color=\"primary\", className=\"mr-1\"),\n",
    "    dbc.Modal(\n",
    "        [\n",
    "            dbc.ModalHeader(\"New Project Details\"),\n",
    "            dbc.ModalBody(\n",
    "                [\n",
    "                    dcc.Input(id='type-input', type='text', placeholder='Type of Project'),\n",
    "                    dcc.Input(id='duration-input', type='text', placeholder='Duration of Project')\n",
    "                ]\n",
    "            ),\n",
    "            dbc.ModalFooter(\n",
    "                [\n",
    "                    dbc.Button(\"Close\", id=\"close\", className=\"ml-auto\"),\n",
    "                    dbc.Button(\"Save Changes\", id=\"save-changes\", className=\"ml-1\")\n",
    "                ]\n",
    "            ),\n",
    "        ],\n",
    "        id=\"modal\",\n",
    "        size='lg',\n",
    "        centered=True,\n",
    "        backdrop='static'\n",
    "    ),\n",
    "    html.Div([\n",
    "        html.Label('Type of Project:'),\n",
    "        dcc.Dropdown(\n",
    "            id='type-dropdown',\n",
    "            options=type_options,\n",
    "            value=type_options[0]['value'] if type_options else None  # Default value\n",
    "        )\n",
    "    ]),\n",
    "    dcc.Dropdown(\n",
    "        id='project-dropdown',\n",
    "        options=project_options,\n",
    "        value=project_options[0]['value']  # Default value\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='job-dropdown',\n",
    "        multi=True,\n",
    "    ),\n",
    "    dcc.Graph(id='deployment-plan'),\n",
    "    html.Div(id='selected-project-type')  # Show the selected project type\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to update job dropdown options based on selected project\n",
    "@app.callback(\n",
    "    Output('job-dropdown', 'options'),\n",
    "    [Input('project-dropdown', 'value')]\n",
    ")\n",
    "def update_job_dropdown(selected_project):\n",
    "    # Filter the DataFrame based on the selected project\n",
    "    filtered_data = df[df['Project'] == selected_project]\n",
    "\n",
    "    # Get unique job titles for the selected project\n",
    "    job_options = [{'label': 'Select All', 'value': 'all'}] + [{'label': job, 'value': job} for job in\n",
    "                                                                filtered_data['Job'].unique()]\n",
    "\n",
    "    return job_options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to update the deployment plan based on selected project and job titles\n",
    "@app.callback(\n",
    "    Output('deployment-plan', 'figure'),\n",
    "    [Input('project-dropdown', 'value'),\n",
    "     Input('job-dropdown', 'value')]\n",
    ")\n",
    "def update_plan(selected_project, selected_jobs):\n",
    "    if not selected_project or not selected_jobs:\n",
    "        # Return an empty figure if no project or job is selected\n",
    "        return {'data': [], 'layout': {}}\n",
    "\n",
    "    if 'all' in selected_jobs:\n",
    "        # If 'Select All' is selected, set selected_jobs to all job titles for the selected project\n",
    "        filtered_data = df[df['Project'] == selected_project]\n",
    "        selected_jobs = filtered_data['Job'].unique()\n",
    "\n",
    "    # Filter the DataFrame based on the selected project and selected job titles\n",
    "    filtered_data = df[(df['Project'] == selected_project) & (df['Job'].isin(selected_jobs))]\n",
    "\n",
    "    if filtered_data.empty:\n",
    "        # Return an empty figure if the filtered data is empty\n",
    "        return {'data': [], 'layout': {}}\n",
    "\n",
    "    # Get unique job titles for the selected project\n",
    "    unique_jobs = filtered_data['Job'].unique()\n",
    "\n",
    "    # Get unique months for the selected project and sort them\n",
    "    months = sorted(filtered_data['Month'].unique())\n",
    "\n",
    "    # Create a matrix to store staff count for each job title in each month\n",
    "    staff_matrix = []\n",
    "\n",
    "    # Iterate through each job title and count staff for each month\n",
    "    for job in unique_jobs:\n",
    "        job_data = filtered_data[filtered_data['Job'] == job]\n",
    "        staff_count = [\n",
    "            job_data[job_data['Month'] == month].shape[0] if not job_data[job_data['Month'] == month].empty else None\n",
    "            for month in months\n",
    "        ]\n",
    "        staff_matrix.append(staff_count)\n",
    "\n",
    "    # Get the maximum staff count for the selected project\n",
    "    max_value = max([item for sublist in staff_matrix for item in sublist if item is not None])\n",
    "\n",
    "    # Create data for the heatmap\n",
    "    data = [\n",
    "        go.Heatmap(\n",
    "            z=staff_matrix,\n",
    "            x=months,\n",
    "            y=unique_jobs,\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            zmin=1,  # Set minimum value for the color scale\n",
    "            zmax=max_value,  # Set maximum value for the color scale\n",
    "            zmid=0,  # Set midpoint value for the color scale\n",
    "            colorbar=dict(tickmode='array', tickvals=list(range(1, max_value + 1)), ticktext=list(range(1, max_value + 1)))\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Define layout for the heatmap\n",
    "    layout = go.Layout(\n",
    "        title=f\"Deployment Plan for {selected_project}\",\n",
    "        xaxis=dict(title='Months'),\n",
    "        yaxis=dict(title='Job Titles'),\n",
    "    )\n",
    "\n",
    "    return {'data': data, 'layout': layout}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New callback for the modal popup\n",
    "@app.callback(\n",
    "    Output(\"modal\", \"is_open\"),\n",
    "    [Input(\"open\", \"n_clicks\"), Input(\"close\", \"n_clicks\"), Input(\"save-changes\", \"n_clicks\")],\n",
    "    [dash.dependencies.State(\"modal\", \"is_open\")],\n",
    ")\n",
    "def toggle_modal(n1, n2, n3, is_open):\n",
    "    if n1 or n2 or n3:\n",
    "        return not is_open\n",
    "    return is_open\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to show the project type for the selected project\n",
    "@app.callback(\n",
    "    Output('selected-project-type', 'children'),\n",
    "    [Input('project-dropdown', 'value')]\n",
    ")\n",
    "def display_project_type(selected_project):\n",
    "    # Get the type of the selected project\n",
    "    project_type = df_types[df_types['Project'] == selected_project]['Type'].values[0]\n",
    "    return f'Type of Project: {project_type}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1ecf92b2600>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
