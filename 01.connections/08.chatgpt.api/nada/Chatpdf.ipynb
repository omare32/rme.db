{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50aa0c0-2508-4c98-8415-c679b0ed13cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849d00e0-660b-425e-a2ed-ea1f98075343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatpdf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatpdf.py\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from htmlTemplates import css, bot_template, user_template\n",
    "\n",
    "\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def get_conversation_chain(vectorstore):\n",
    "    llm = ChatOpenAI()\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history', return_messages=True)\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "    return conversation_chain\n",
    "\n",
    "\n",
    "def handle_userinput(user_question):\n",
    "    response = st.session_state.conversation({'question': user_question})\n",
    "    st.session_state.chat_history = response['chat_history']\n",
    "\n",
    "    for i, message in enumerate(st.session_state.chat_history):\n",
    "        if i % 2 == 0:\n",
    "            st.write(user_template.replace(\n",
    "                \"{{MSG}}\", message.content), unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.write(bot_template.replace(\n",
    "                \"{{MSG}}\", message.content), unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    load_dotenv()\n",
    "    st.set_page_config(page_title=\"Chat with multiple PDFs\",\n",
    "                       page_icon=\":books:\")\n",
    "    st.write(css, unsafe_allow_html=True)\n",
    "\n",
    "    if \"conversation\" not in st.session_state:\n",
    "        st.session_state.conversation = None\n",
    "    if \"chat_history\" not in st.session_state:\n",
    "        st.session_state.chat_history = None\n",
    "\n",
    "    st.header(\"Chat with multiple PDFs :books:\")\n",
    "    user_question = st.text_input(\"Ask a question about your documents:\")\n",
    "    if user_question:\n",
    "        handle_userinput(user_question)\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.subheader(\"Your documents\")\n",
    "        pdf_docs = st.file_uploader(\n",
    "            \"Upload your PDFs here and click on 'Process'\", accept_multiple_files=True)\n",
    "        if st.button(\"Process\"):\n",
    "            with st.spinner(\"Processing\"):\n",
    "                # get pdf text\n",
    "                raw_text = get_pdf_text(pdf_docs)\n",
    "\n",
    "                # get the text chunks\n",
    "                text_chunks = get_text_chunks(raw_text)\n",
    "\n",
    "                # create vector store\n",
    "                vectorstore = get_vectorstore(text_chunks)\n",
    "\n",
    "                # create conversation chain\n",
    "                st.session_state.conversation = get_conversation_chain(\n",
    "                    vectorstore)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b229e23c-6ffd-4d86-b67f-27b5012c7e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run chatpdf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afb62e-e5c5-4035-8178-5d82c52a4fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
