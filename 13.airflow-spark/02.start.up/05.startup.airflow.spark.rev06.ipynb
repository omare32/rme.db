{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to 10.10.11.242...\n",
      "Executing: cd ~/airflow\n",
      "Executing: source airflow/venv/bin/activate && airflow db migrate\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/home/PMO/airflow/venv/bin/airflow\", line 5, in <module>\n",
      "    from airflow.__main__ import main\n",
      "ModuleNotFoundError: No module named 'airflow'\n",
      "\n",
      "Executing: source airflow/venv/bin/activate && airflow scheduler -D\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/home/PMO/airflow/venv/bin/airflow\", line 5, in <module>\n",
      "    from airflow.__main__ import main\n",
      "ModuleNotFoundError: No module named 'airflow'\n",
      "\n",
      "Executing: source airflow/venv/bin/activate && airflow webserver -D --port 8090\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"/home/PMO/airflow/venv/bin/airflow\", line 5, in <module>\n",
      "    from airflow.__main__ import main\n",
      "ModuleNotFoundError: No module named 'airflow'\n",
      "\n",
      "Executing: echo PMO@1234 | sudo -S /opt/spark/sbin/start-master.sh -i 10.10.11.242 --webui-port 8080\n",
      "Output: org.apache.spark.deploy.master.Master running as process 4246.  Stop it first.\n",
      "\n",
      "Error: [sudo] password for PMO: \n",
      "Executing: echo PMO@1234 | sudo -S /opt/spark/sbin/start-worker.sh spark://10.10.11.242:7077\n",
      "Output: org.apache.spark.deploy.worker.Worker running as process 4368.  Stop it first.\n",
      "\n",
      "Error: [sudo] password for PMO: \n",
      "Executing: echo PMO@1234 | sudo -S jps\n",
      "Output: 4368 Worker\n",
      "4246 Master\n",
      "4647 Jps\n",
      "\n",
      "Error: [sudo] password for PMO: \n",
      "All commands executed successfully.\n"
     ]
    }
   ],
   "source": [
    "import paramiko\n",
    "\n",
    "# SSH details\n",
    "host = \"10.10.11.242\"\n",
    "username = \"PMO\"\n",
    "password = \"PMO@1234\"\n",
    "sudo_password = \"PMO@1234\"\n",
    "\n",
    "# Commands to run on the server\n",
    "commands = [\n",
    "    \"cd ~/airflow\",\n",
    "    \"source airflow/venv/bin/activate && airflow db migrate\",\n",
    "    \"source airflow/venv/bin/activate && airflow scheduler -D\",\n",
    "    \"source airflow/venv/bin/activate && airflow webserver -D --port 8090\",\n",
    "    f\"echo {sudo_password} | sudo -S /opt/spark/sbin/start-master.sh -i 10.10.11.242 --webui-port 8080\",\n",
    "    f\"echo {sudo_password} | sudo -S /opt/spark/sbin/start-worker.sh spark://10.10.11.242:7077\",\n",
    "    f\"echo {sudo_password} | sudo -S jps\"\n",
    "]\n",
    "\n",
    "def execute_ssh_commands(host, username, password, commands):\n",
    "    try:\n",
    "        # Create SSH client\n",
    "        client = paramiko.SSHClient()\n",
    "        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "        # Connect to the server\n",
    "        print(f\"Connecting to {host}...\")\n",
    "        client.connect(hostname=host, username=username, password=password)\n",
    "\n",
    "        # Execute each command\n",
    "        for command in commands:\n",
    "            print(f\"Executing: {command}\")\n",
    "            stdin, stdout, stderr = client.exec_command(command)\n",
    "            stdout_result = stdout.read().decode()\n",
    "            stderr_result = stderr.read().decode()\n",
    "\n",
    "            if stdout_result:\n",
    "                print(f\"Output: {stdout_result}\")\n",
    "            if stderr_result:\n",
    "                print(f\"Error: {stderr_result}\")\n",
    "\n",
    "        # Close the connection\n",
    "        client.close()\n",
    "        print(\"All commands executed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Run the function\n",
    "execute_ssh_commands(host, username, password, commands)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
