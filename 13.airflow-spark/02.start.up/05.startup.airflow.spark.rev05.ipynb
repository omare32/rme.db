{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to 10.10.11.242...\n",
      "Executing: cd ~/airflow\n",
      "\n",
      "\n",
      "Executing: source airflow/venv/bin/activate && airflow db migrate\n",
      "DB: mysql+mysqldb://gamal:***@10.10.11.242/RME_DH\n",
      "Performing upgrade to the metadata database mysql+mysqldb://gamal:***@10.10.11.242/RME_DH\n",
      "[2025-01-23T13:26:19.437+0200] {migration.py:215} INFO - Context impl MySQLImpl.\n",
      "[2025-01-23T13:26:19.439+0200] {migration.py:218} INFO - Will assume non-transactional DDL.\n",
      "[2025-01-23T13:26:19.443+0200] {migration.py:215} INFO - Context impl MySQLImpl.\n",
      "[2025-01-23T13:26:19.443+0200] {migration.py:218} INFO - Will assume non-transactional DDL.\n",
      "[2025-01-23T13:26:19.445+0200] {db.py:1674} INFO - Creating tables\n",
      "Database migrating done!\n",
      "\n",
      "INFO  [alembic.runtime.migration] Context impl MySQLImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl MySQLImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "\n",
      "Executing: source airflow/venv/bin/activate && airflow webserver -D\n",
      "  ____________       _____________\n",
      " ____    |__( )_________  __/__  /________      __\n",
      "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
      "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
      " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
      "Running the Gunicorn Server with:\n",
      "Workers: 4 sync\n",
      "Host: 0.0.0.0:8080\n",
      "Timeout: 120\n",
      "Logfiles: - -\n",
      "Access Logformat: \n",
      "=================================================================\n",
      "[2025-01-23T13:26:21.062+0200] {dagbag.py:588} INFO - Filling up the DagBag from /dev/null\n",
      "\n",
      "/home/PMO/airflow/venv/lib/python3.10/site-packages/flask_limiter/extension.py:333 UserWarning: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for production use. See: https://flask-limiter.readthedocs.io#configuring-a-storage-backend for documentation about configuring the storage backend.\n",
      "/home/PMO/airflow/venv/lib/python3.10/site-packages/airflow/www/app.py:178 RemovedInAirflow3Warning: The experimental REST API is deprecated. Please migrate to the stable REST API. Please note that the experimental API do not have access control. The authenticated user has full access.\n",
      "/home/PMO/airflow/venv/lib/python3.10/site-packages/airflow/providers/fab/auth_manager/fab_auth_manager.py:523 FutureWarning: section/key [webserver/update_fab_perms] has been deprecated, you should use[fab/update_fab_perms] instead. Please update your `conf.get*` call to use the new name\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/PMO/airflow/venv/bin/airflow\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/PMO/airflow/venv/lib/python3.10/site-packages/airflow/__main__.py\", line 62, in main\n",
      "    args.func(args)\n",
      "  File \"/home/PMO/airflow/venv/lib/python3.10/site-packages/airflow/cli/cli_config.py\", line 49, in command\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/PMO/airflow/venv/lib/python3.10/site-packages/airflow/utils/cli.py\", line 115, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/PMO/airflow/venv/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py\", line 55, in wrapped_function\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/PMO/airflow/venv/lib/python3.10/site-packages/airflow/cli/commands/webserver_command.py\", line 485, in webserver\n",
      "    run_command_with_daemon_option(\n",
      "  File \"/home/PMO/airflow/venv/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py\", line 58, in run_command_with_daemon_option\n",
      "    check_if_pidfile_process_is_running(pid_file=pid, process_name=process_name)\n",
      "  File \"/home/PMO/airflow/venv/lib/python3.10/site-packages/airflow/utils/process_utils.py\", line 328, in check_if_pidfile_process_is_running\n",
      "    raise AirflowException(f\"The {process_name} is already running under PID {pid}.\")\n",
      "airflow.exceptions.AirflowException: The webserver is already running under PID 1673.\n",
      "\n",
      "Executing: source airflow/venv/bin/activate && airflow scheduler -D\n",
      "  ____________       _____________\n",
      " ____    |__( )_________  __/__  /________      __\n",
      "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
      "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
      " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
      "[2025-01-23T13:26:24.939+0200] {_client.py:1026} INFO - HTTP Request: GET https://apacheairflow.gateway.scarf.sh/scheduler?version=2.10.2&python_version=3.10&platform=Linux&arch=x86_64&database=mysql&db_version=8.0&executor=LocalExecutor \"HTTP/1.1 200 OK\"\n",
      "\n",
      "\n",
      "Executing: echo PMO@1234 | sudo -S /opt/spark/sbin/start-master.sh -i 10.10.11.242 --webui-port 8080\n",
      "starting org.apache.spark.deploy.master.Master, logging to /opt/spark/logs/spark-root-org.apache.spark.deploy.master.Master-1-PMO.out\n",
      "\n",
      "[sudo] password for PMO: \n",
      "Executing: echo PMO@1234 | sudo -S /opt/spark/sbin/start-worker.sh spark://10.10.11.242:7077\n",
      "starting org.apache.spark.deploy.worker.Worker, logging to /opt/spark/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-PMO.out\n",
      "\n",
      "[sudo] password for PMO: \n",
      "Executing: echo PMO@1234 | sudo -S jps\n",
      "4233 Jps\n",
      "3897 Worker\n",
      "3580 Master\n",
      "\n",
      "[sudo] password for PMO: \n",
      "All commands executed successfully.\n"
     ]
    }
   ],
   "source": [
    "import paramiko\n",
    "\n",
    "# SSH details\n",
    "host = \"10.10.11.242\"\n",
    "username = \"PMO\"\n",
    "password = \"PMO@1234\"\n",
    "sudo_password = \"PMO@1234\"\n",
    "\n",
    "# Commands to run on the server\n",
    "commands = [\n",
    "    \"cd ~/airflow\",\n",
    "    \"source airflow/venv/bin/activate && airflow db migrate\",\n",
    "    \"source airflow/venv/bin/activate && airflow webserver -D\",\n",
    "    \"source airflow/venv/bin/activate && airflow scheduler -D\",\n",
    "    f\"echo {sudo_password} | sudo -S /opt/spark/sbin/start-master.sh -i 10.10.11.242 --webui-port 8080\",\n",
    "    f\"echo {sudo_password} | sudo -S /opt/spark/sbin/start-worker.sh spark://10.10.11.242:7077\",\n",
    "    f\"echo {sudo_password} | sudo -S jps\"\n",
    "]\n",
    "\n",
    "\n",
    "def execute_ssh_commands(host, username, password, commands):\n",
    "    try:\n",
    "        # Create SSH client\n",
    "        client = paramiko.SSHClient()\n",
    "        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "        # Connect to the server\n",
    "        print(f\"Connecting to {host}...\")\n",
    "        client.connect(hostname=host, username=username, password=password)\n",
    "\n",
    "        # Execute each command\n",
    "        for command in commands:\n",
    "            print(f\"Executing: {command}\")\n",
    "            stdin, stdout, stderr = client.exec_command(command)\n",
    "            print(stdout.read().decode())\n",
    "            print(stderr.read().decode())\n",
    "\n",
    "        # Close the connection\n",
    "        client.close()\n",
    "        print(\"All commands executed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Run the function\n",
    "execute_ssh_commands(host, username, password, commands)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
