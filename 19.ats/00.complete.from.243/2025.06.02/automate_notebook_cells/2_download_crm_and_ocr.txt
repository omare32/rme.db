# Step 1: Download CVs from CRM and update database (last 3 days, with detailed logging)
print("[CRM] Starting CRM fetch and download process...")
from datetime import datetime, timedelta

def get_session():
    session = requests.Session()
    session.auth = HttpNtlmAuth(USERNAME, PASSWORD)
    session.headers.update({
        "Accept": "application/json",
        "OData-MaxVersion": "4.0",
        "OData-Version": "4.0"
    })
    return session

# Always fetch the last 3 days (not using MAX(createdon))
def get_job_applications(session):
    all_applications = []
    end_date = datetime.now()
    start_date = end_date - timedelta(days=3)
    print(f"[CRM] Fetching applications from {start_date} to {end_date.date()}")
    filter_condition = (
        f"createdon ge {start_date.strftime('%Y-%m-%dT00:00:00Z')} "
        f"and createdon le {end_date.strftime('%Y-%m-%dT23:59:59Z')}"
    )
    url = (
        f"{CRM_URL}/new_jobapplications?"
        f"$select=new_jobapplicationid,new_name,new_email,new_jauid,createdon&"
        f"$filter={quote(filter_condition)}&"
        "$top=5000"
    )
    try:
        response = session.get(url)
        response.raise_for_status()
        data = response.json()
        if "value" in data:
            applications = data["value"]
            print(f"[CRM] Found {len(applications)} applications in the last 3 days")
            for app in applications:
                print(f"  [CRM] AppID: {app.get('new_jobapplicationid')} | Name: {app.get('new_name')} | Created: {app.get('createdon')}")
                annotations_url = (
                    f"{CRM_URL}/annotations?"
                    f"$filter=_objectid_value eq {app['new_jobapplicationid']}&"
                    "$select=filename,mimetype,documentbody"
                )
                try:
                    annotations_response = session.get(annotations_url)
                    annotations_response.raise_for_status()
                    annotations_data = annotations_response.json()
                    if "value" in annotations_data:
                        app["annotations"] = annotations_data["value"]
                        for annotation in annotations_data["value"]:
                            print(f"    [CRM] Annotation filename: {annotation.get('filename')}")
                    else:
                        app["annotations"] = []
                except requests.exceptions.RequestException as e:
                    print(f"[CRM][ERROR] Error fetching annotations for application {app['new_jobapplicationid']}: {str(e)}")
                    app["annotations"] = []
            all_applications.extend(applications)
            print(f"[CRM] Total applications fetched: {len(all_applications)}")
    except requests.exceptions.RequestException as e:
        print(f"[CRM][ERROR] Error fetching applications: {str(e)}")
    return all_applications

def get_last_extracted_date():
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    try:
        cursor.execute("SELECT MAX(createdon) FROM pdf_extracted_data")
        last_date = cursor.fetchone()[0]
        if last_date:
            print(f"[CRM] Last extracted date from DB: {last_date}")
            return last_date
        else:
            print("[CRM] No previous extraction found, defaulting to 3 days ago.")
            return datetime.now() - timedelta(days=3)
    except Exception as e:
        print(f"[CRM][ERROR] Error fetching last extracted date: {e}")
        return datetime.now() - timedelta(days=3)
    finally:
        cursor.close()
        conn.close()

def download_attachments(applications):
    if not os.path.exists(DOWNLOAD_DIR):
        os.makedirs(DOWNLOAD_DIR)
    downloaded = 0
    skipped = 0
    for app in applications:
        try:
            app_id = app.get("new_jobapplicationid")
            created_date = app.get("createdon", "").split("T")[0]
            annotations = app.get("annotations", [])
            for annotation in annotations:
                if "documentbody" in annotation and "filename" in annotation:
                    filename = annotation["filename"]
                    if filename.lower().endswith((".pdf", ".doc", ".docx")):
                        try:
                            unique_filename = f"{created_date}_{filename}"
                            file_path = os.path.join(DOWNLOAD_DIR, unique_filename)
                            if os.path.exists(file_path):
                                print(f"[CRM] Skipping existing file: {unique_filename}")
                                skipped += 1
                                continue
                            file_content = base64.b64decode(annotation["documentbody"])
                            with open(file_path, "wb") as f:
                                f.write(file_content)
                            print(f"[CRM] Downloaded: {unique_filename}")
                            downloaded += 1
                        except Exception as e:
                            print(f"[CRM][ERROR] Error saving file {filename}: {e}")
        except Exception as e:
            print(f"[CRM][ERROR] Error processing application {app.get('new_jobapplicationid')}: {e}")
    print(f"[CRM] Downloaded {downloaded} new files, skipped {skipped} existing files.")
    return downloaded, skipped

def update_db_with_extra_columns(applications):
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    updated = 0
    try:
        for app in applications:
            app_id = app.get("new_jobapplicationid")
            name = app.get("new_name")
            email = app.get("new_email")
            jauid = app.get("new_jauid")
            if not app_id:
                continue
            cursor.execute("""
                UPDATE pdf_extracted_data SET
                    crm_name2 = %s,
                    crm_email2 = %s,
                    crm_jauid2 = %s
                WHERE crm_applicationid = %s
            """, (name, email, jauid, app_id))
            if cursor.rowcount > 0:
                updated += cursor.rowcount
        conn.commit()
        print(f"[CRM] Updated {updated} rows with extra CRM columns.")
    except Exception as e:
        print(f"[CRM][ERROR] Error updating database: {e}")
        conn.rollback()
    finally:
        cursor.close()
        conn.close()

print("[CRM] Fetching and downloading from CRM complete.\n")

# Step 2: Extract OCR text from PDFs and store in database
print("[OCR] Starting OCR extraction for new PDFs...")
def setup_database():
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS pdf_extracted_data (
                id SERIAL PRIMARY KEY,
                pdf_filename VARCHAR(255),
                ocr_result TEXT,
                name VARCHAR(255),
                email VARCHAR(255),
                phone VARCHAR(255),
                linkedin VARCHAR(255),
                graduation_year VARCHAR(255),
                university VARCHAR(255),
                skills TEXT,
                department VARCHAR(255),
                job_title VARCHAR(255),
                years_of_experience VARCHAR(50),
                current_company VARCHAR(255),
                location VARCHAR(255),
                languages TEXT,
                certifications TEXT,
                project_types TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        conn.commit()
        return conn, cursor
    except Exception as e:
        print(f"[OCR][ERROR] Database connection error: {e}")
        return None, None

def extract_text_from_pdf(pdf_path):
    try:
        images = convert_from_path(
            pdf_path,
            poppler_path=POPPLER_PATH
        )
        text = ""
        for img in images:
            try:
                text += pytesseract.image_to_string(img) + "\n"
            except Exception as e:
                print(f"[OCR][ERROR] OCR error on page: {e}")
                continue
        return text.strip()
    except Exception as e:
        print(f"[OCR][ERROR] Error processing PDF {pdf_path}: {e}")
        return None

def process_pdfs_in_directory(directory_path):
    conn, cursor = setup_database()
    if not conn or not cursor:
        print("[OCR][ERROR] Failed to setup database connection. Exiting.")
        return
    os.makedirs(directory_path, exist_ok=True)
    conn.autocommit = False
    try:
        cursor.execute("SELECT pdf_filename FROM pdf_extracted_data WHERE ocr_result IS NOT NULL")
        processed_files = {row[0] for row in cursor.fetchall()}
        print(f"[OCR] Found {len(processed_files)} already processed files in database")
        new_files = 0
        failed_files = 0
        for filename in os.listdir(directory_path):
            if filename.endswith(".pdf"):
                if filename in processed_files:
                    print(f"[OCR] Skipping already processed file: {filename}")
                    continue
                file_path = os.path.join(directory_path, filename)
                print(f"[OCR] Processing new file: {filename}")
                new_files += 1
                ocr_text = extract_text_from_pdf(file_path)
                if not ocr_text:
                    print(f"[OCR][ERROR] Failed to extract text from {filename}")
                    failed_files += 1
                    continue
                try:
                    cursor.execute("SELECT id FROM pdf_extracted_data WHERE pdf_filename = %s", (filename,))
                    if cursor.fetchone():
                        print(f"[OCR] File was processed by another process while we were working: {filename}")
                        continue
                    cursor.execute(
                        """
                        INSERT INTO pdf_extracted_data 
                        (pdf_filename, ocr_result)
                        VALUES (%s, %s)
                        """,
                        (filename, ocr_text)
                    )
                    conn.commit()
                    print(f"[OCR] ✓ Successfully saved OCR text for: {filename}")
                except Exception as e:
                    print(f"[OCR][ERROR] Database insertion error for {filename}: {e}")
                    conn.rollback()
                    failed_files += 1
                    continue
        print(f"[OCR] OCR Processing completed: {new_files - failed_files} files processed, {failed_files} failed, {new_files} total attempted.")
    except Exception as e:
        print(f"[OCR][ERROR] Error during processing: {e}")
        conn.rollback()
    finally:
        conn.autocommit = True
        cursor.close()
        conn.close()
print("[OCR] OCR extraction complete.\n") 