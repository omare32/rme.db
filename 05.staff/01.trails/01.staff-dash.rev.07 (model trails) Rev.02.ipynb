{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from Excel files\n",
    "staff_data = pd.read_excel('staff.xlsx')  # Replace 'path_to_staff.xlsx' with the actual path\n",
    "types_data = pd.read_excel('types.xlsx')  # Replace 'path_to_types.xlsx' with the actual path\n",
    "\n",
    "# Merge the data based on the 'Project' column\n",
    "merged_data = staff_data.merge(types_data, on='Project', how='inner')\n",
    "\n",
    "# Calculate maximum job number for each job in a month for each project\n",
    "max_job_numbers = merged_data.groupby(['Type', 'Job', 'Project']).agg({'Month': 'count'}).reset_index()\n",
    "max_job_numbers = max_job_numbers.rename(columns={'Month': 'Number_of_Jobs'})\n",
    "\n",
    "# Calculate average maximum job number rounded down\n",
    "average_max_job_number = math.floor(max_job_numbers['Number_of_Jobs'].mean())\n",
    "\n",
    "# Calculate average start and end months for each job title in a project\n",
    "avg_start_end = staff_data.groupby(['Job', 'Project']).agg({'Month': ['min', 'max']}).reset_index()\n",
    "avg_start_end.columns = ['Job', 'Project', 'Start_Month', 'End_Month']\n",
    "\n",
    "# Create the new project using the calculated averages\n",
    "new_project = {\n",
    "    'Job_Title': [],\n",
    "    'Start_Month': [],\n",
    "    'End_Month': [],\n",
    "    'Number_of_Jobs': []\n",
    "}\n",
    "\n",
    "for index, row in avg_start_end.iterrows():\n",
    "    new_project['Job_Title'].append(row['Job'])\n",
    "    new_project['Start_Month'].append(row['Start_Month'].month)\n",
    "    new_project['End_Month'].append(row['End_Month'].month)\n",
    "    new_project['Number_of_Jobs'].append(average_max_job_number)  # Using the calculated average max job number\n",
    "\n",
    "\n",
    "# Create final_df DataFrame\n",
    "final_df = pd.DataFrame(new_project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Job    Project      Month        Type\n",
      "0              سائق لودر  Beni Suef 2015-10-01  Industrial\n",
      "1             Storekeepe  Beni Suef 2015-10-01  Industrial\n",
      "2  Survyour Section Head  Beni Suef 2015-10-01  Industrial\n",
      "3                Foreman  Beni Suef 2015-10-01  Industrial\n",
      "4                Foreman  Beni Suef 2015-10-01  Industrial\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from Excel files\n",
    "staff_data = pd.read_excel('staff.xlsx')  # Replace 'path_to_staff.xlsx' with the actual path\n",
    "types_data = pd.read_excel('types.xlsx')  # Replace 'path_to_types.xlsx' with the actual path\n",
    "\n",
    "# Merge the data based on the 'Project' column\n",
    "final_df = pd.merge(staff_data, types_data, on='Project')\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Job    Project      Month\n",
      "0                  سائق لودر  Beni Suef 2015-10-01\n",
      "1              Site Engineer        Tb2 2015-10-01\n",
      "2          Project Manager .        Tb2 2015-10-01\n",
      "3              Site Engineer        Tb2 2015-10-01\n",
      "4  Technical Office Engineer        Tb2 2015-10-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the staff data from 'staff.xlsx'\n",
    "staff_data = pd.read_excel('staff.xlsx')\n",
    "\n",
    "# Display the first few rows to ensure the data is loaded correctly\n",
    "print(staff_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average max job number: 20\n",
      "                  Project                    Job  Peak_Number  \\\n",
      "0  10th of Ramadan Bridge  Blacksmith Supervisor            3   \n",
      "1  10th of Ramadan Bridge   Carpenter Supervisor            2   \n",
      "2  10th of Ramadan Bridge   Construction Foreman            3   \n",
      "3  10th of Ramadan Bridge   Construction Manager            4   \n",
      "4  10th of Ramadan Bridge    Document Controller            2   \n",
      "\n",
      "  Average_Start_Month Average_End_Month  \n",
      "0          2020-06-01        2020-08-01  \n",
      "1          2020-06-01        2020-07-01  \n",
      "2          2020-05-01        2020-07-01  \n",
      "3          2020-05-01        2020-08-01  \n",
      "4          2020-06-01        2020-07-01  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'Month' column to datetime if it's not already in datetime format\n",
    "staff_data['Month'] = pd.to_datetime(staff_data['Month'])\n",
    "\n",
    "# Group by 'Project' and 'Job' to calculate the peak number of employees and average start/end months\n",
    "grouped_data = staff_data.groupby(['Project', 'Job']).agg(\n",
    "    Peak_Number=('Job', 'count'),\n",
    "    Average_Start_Month=('Month', 'min'),\n",
    "    Average_End_Month=('Month', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the average peak number for each job across all projects\n",
    "average_max_job_number = grouped_data['Peak_Number'].mean()\n",
    "\n",
    "# Round down the average max job number to the nearest whole number\n",
    "average_max_job_number = int(average_max_job_number)\n",
    "\n",
    "# Display the results\n",
    "print(\"Average max job number:\", average_max_job_number)\n",
    "print(grouped_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Job               Project  \\\n",
      "0                                   سائق لودر             Beni Suef   \n",
      "1                                  Storekeepe             Beni Suef   \n",
      "2                       Survyour Section Head             Beni Suef   \n",
      "3                                     Foreman             Beni Suef   \n",
      "4                                     Foreman             Beni Suef   \n",
      "...                                       ...                   ...   \n",
      "105564                          Site Engineer  Qasr Rashwan Lot – B   \n",
      "105565              Site Team Leader Engineer  Qasr Rashwan Lot – B   \n",
      "105566                               Surveyor  Qasr Rashwan Lot – B   \n",
      "105567  Technical Office Team Leader Engineer  Qasr Rashwan Lot – B   \n",
      "105568                          Site Engineer  Qasr Rashwan Lot – B   \n",
      "\n",
      "            Month          Type_x          Type_y            Type  \n",
      "0      2015-10-01      Industrial      Industrial      Industrial  \n",
      "1      2015-10-01      Industrial      Industrial      Industrial  \n",
      "2      2015-10-01      Industrial      Industrial      Industrial  \n",
      "3      2015-10-01      Industrial      Industrial      Industrial  \n",
      "4      2015-10-01      Industrial      Industrial      Industrial  \n",
      "...           ...             ...             ...             ...  \n",
      "105564 2023-11-01  Infrastructure  Infrastructure  Infrastructure  \n",
      "105565 2023-11-01  Infrastructure  Infrastructure  Infrastructure  \n",
      "105566 2023-11-01  Infrastructure  Infrastructure  Infrastructure  \n",
      "105567 2023-11-01  Infrastructure  Infrastructure  Infrastructure  \n",
      "105568 2023-11-01  Infrastructure  Infrastructure  Infrastructure  \n",
      "\n",
      "[105569 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print (final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Passing 'suffixes' which cause duplicate columns {'Type_x'} is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProject\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Now 'final_df' should contain the 'Type' column\u001b[39;00m\n\u001b[0;32m      4\u001b[0m user_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the type: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:162\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    148\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    149\u001b[0m         left,\n\u001b[0;32m    150\u001b[0m         right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:811\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    809\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 811\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:763\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    760\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft[:]\n\u001b[0;32m    761\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright[:]\n\u001b[1;32m--> 763\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m \u001b[43m_items_overlap_with_suffix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuffixes\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[0;32m    771\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    772\u001b[0m         join_index,\n\u001b[0;32m    773\u001b[0m         left_indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    778\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    779\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2626\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, right, suffixes)\u001b[0m\n\u001b[0;32m   2624\u001b[0m     dups\u001b[38;5;241m.\u001b[39mextend(rlabels[(rlabels\u001b[38;5;241m.\u001b[39mduplicated()) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;241m~\u001b[39mright\u001b[38;5;241m.\u001b[39mduplicated())]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m   2625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dups:\n\u001b[1;32m-> 2626\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[0;32m   2627\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuffixes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m which cause duplicate columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(dups)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2628\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2629\u001b[0m     )\n\u001b[0;32m   2631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llabels, rlabels\n",
      "\u001b[1;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'Type_x'} is not allowed."
     ]
    }
   ],
   "source": [
    "final_df = pd.merge(final_df, types_data, on='Project')\n",
    "\n",
    "# Now 'final_df' should contain the 'Type' column\n",
    "user_type = input(\"Enter the type: \")\n",
    "filtered_df = final_df[final_df['Type'] == user_type]\n",
    "# Proceed with calculating start and end months for the new deployment plan using filtered_df\n",
    "\n",
    "\n",
    "# Calculate the start and end months for the new deployment plan:\n",
    "number_of_months = int(input(\"Enter the number of months: \"))  # Assuming user inputs the number of months\n",
    "\n",
    "# Calculate start and end months\n",
    "start_month = filtered_df['Start_Month'].mean()  # Get the average start month\n",
    "end_month = start_month + number_of_months  # Calculate the end month\n",
    "\n",
    "# Ensure the end month does not exceed the maximum end month in the dataset\n",
    "max_end_month = filtered_df['End_Month'].max()\n",
    "if end_month > max_end_month:\n",
    "    end_month = max_end_month\n",
    "\n",
    "#Create the new deployment plan:\n",
    "new_deployment_plan = {\n",
    "    'Type': user_type,\n",
    "    'Start_Month': int(start_month),\n",
    "    'End_Month': int(end_month),\n",
    "    'Number_of_Jobs': filtered_df['Number_of_Jobs'].iloc[0]  # Assuming the number of jobs remains constant\n",
    "}\n",
    "\n",
    "print(\"New Deployment Plan:\")\n",
    "print(new_deployment_plan)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
